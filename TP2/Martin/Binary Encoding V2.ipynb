{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/martin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "import datetime \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import unidecode\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "import sklearn as sk\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "import category_encoders as ce\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import sort\n",
    "from matplotlib import pyplot\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.metrics import accuracy_score, r2_score, classification_report, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm.sklearn import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../train.csv', low_memory=False)\n",
    "test = pd.read_csv('../../test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(x,char):\n",
    "    words = \"\"\n",
    "    for word in x:\n",
    "        if word.startswith(char):\n",
    "            words = words + word + \" \"\n",
    "    return words\n",
    "\n",
    "def count_vowels(x):\n",
    "    return (x.count('a') + x.count('e') + x.count('i') + x.count('o') + x.count('u'))\n",
    "\n",
    "def count_short_words(x):\n",
    "    count = 0\n",
    "    words = x.split(' ')\n",
    "    for word in words:\n",
    "        if 1 <= len(word) <= 3:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_stopwords(x):\n",
    "    count = 0\n",
    "    words = x.split(' ')\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):        \n",
    "    clean_word = ''.join([char for char in word if char not in string.punctuation])\n",
    "    return clean_word\n",
    "\n",
    "def cleaning_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    text_tokenize = tokenizer.tokenize(text)\n",
    "    wordlist = []\n",
    "    for word in text_tokenize:\n",
    "        word = word.lower()\n",
    "        word = re.sub('(?P<url>https?://[^\\s]+)', ' ', word)\n",
    "        word = remove_punctuation(word)\n",
    "        word = re.sub(r'[^\\w]', ' ', word)\n",
    "        word = unidecode.unidecode(word)\n",
    "        word = re.sub(r'[0-9]','', word)\n",
    "        if((word != '')&(word != ' ')&(word not in stopwords)):\n",
    "            wordlist.append(word)\n",
    "    clean_text = ' '.join(wordlist)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>words_count</th>\n",
       "      <th>vowels_count</th>\n",
       "      <th>short_words_count</th>\n",
       "      <th>stopwords_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0       1                    1         #earthquake                       1   \n",
       "1       1                    1                                           0   \n",
       "2       1                    3                                           0   \n",
       "3       1                    2          #wildfires                       1   \n",
       "4       1                    2  #alaska #wildfires                       2   \n",
       "\n",
       "   labels_count  num_chars_count  \\\n",
       "0             0                0   \n",
       "1             0                0   \n",
       "2             0                0   \n",
       "3             0                5   \n",
       "4             0                0   \n",
       "\n",
       "                                          clean_text  text_length  \\\n",
       "0       deeds reason earthquake may allah forgive us           68   \n",
       "1              forest fire near la ronge sask canada           37   \n",
       "2  residents asked shelter place notified officer...          130   \n",
       "3  people receive wildfires evacuation orders cal...           56   \n",
       "4  got sent photo ruby alaska smoke wildfires pou...           84   \n",
       "\n",
       "   words_count  vowels_count  short_words_count  stopwords_count  \n",
       "0           13            25                  7                6  \n",
       "1            7            13                  1                0  \n",
       "2           22            45                  9               11  \n",
       "3            7            24                  1                1  \n",
       "4           16            24                  2                6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"special_chars_count\"] =  train[\"text\"]\n",
    "train[\"special_chars_count\"] =  train[\"special_chars_count\"].str.lower()\n",
    "train[\"special_chars_count\"] = train[\"special_chars_count\"].apply(lambda x: re.sub(r'[a-z]','',x))\n",
    "train[\"special_chars_count\"] = train[\"special_chars_count\"].str.strip()\n",
    "train[\"special_chars_count\"] = train[\"special_chars_count\"].apply(lambda x: re.sub(' +','', x))\n",
    "train[\"special_chars_count\"] = train[\"special_chars_count\"].apply(lambda x: re.sub(r'[0-9]','', x))\n",
    "train[\"special_chars_count\"] = train[\"special_chars_count\"].str.len()\n",
    "\n",
    "train[\"hashtags\"] = train[\"text\"].str.lower().str.split(' ').apply(lambda x: concatenate(x,'#'))\n",
    "train[\"labels\"] = train[\"text\"].str.lower().str.split(' ').apply(lambda x: concatenate(x,'@'))\n",
    "train[\"hashtags_count\"] = train[\"hashtags\"].str.split(' ').apply(lambda x: len(x))-1\n",
    "train[\"labels_count\"] = train[\"labels\"].str.split(' ').apply(lambda x: len(x))-1\n",
    "\n",
    "train[\"num_chars_count\"] = train[\"text\"]\n",
    "train[\"num_chars_count\"] =  train[\"num_chars_count\"].str.lower()\n",
    "train[\"num_chars_count\"] = train[\"num_chars_count\"].apply(lambda x: re.sub(r'[a-z]','',x))\n",
    "train[\"num_chars_count\"] = train[\"num_chars_count\"].apply(lambda x: re.sub(r'[^\\w]','',x))\n",
    "train[\"num_chars_count\"] = train[\"num_chars_count\"].str.strip()\n",
    "train[\"num_chars_count\"] = train[\"num_chars_count\"].str.len()\n",
    "\n",
    "train[\"clean_text\"] = train[\"text\"].apply(lambda x: cleaning_text(x))\n",
    "\n",
    "train[\"text\"] = train[\"text\"].str.lower()\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: re.sub('(?P<url>https?://[^\\s]+)', ' ', x))\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: re.sub(r'_', ' ', x))\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: re.sub(r'[0-9]',' ', x))\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: re.sub(' +',' ', x))\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: re.sub(r'\\b\\w{1}\\b', '', x))\n",
    "train[\"text\"] = train[\"text\"].apply(lambda x: unidecode.unidecode(x))\n",
    "train[\"text\"] = train[\"text\"].str.strip()\n",
    "train[\"text_length\"] = train[\"text\"].str.len()\n",
    "train[\"words_count\"] = train[\"text\"].str.split(' ').apply(lambda x: len(x))\n",
    "\n",
    "train[\"keyword\"] = train[\"keyword\"].str.replace('%20',' ')\n",
    "\n",
    "train[\"vowels_count\"] = train[\"text\"].apply(lambda x: count_vowels(x))\n",
    "train[\"short_words_count\"] = train[\"text\"].apply(lambda x: count_short_words(x))\n",
    "train[\"stopwords_count\"] = train[\"text\"].apply(lambda x: count_stopwords(x))\n",
    "\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>words_count</th>\n",
       "      <th>vowels_count</th>\n",
       "      <th>short_words_count</th>\n",
       "      <th>stopwords_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened  terrible car crash</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>3</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is  forest fire at spot pond geese are f...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "      <td>92</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>3</td>\n",
       "      <td>#spokane #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                  just happened  terrible car crash   \n",
       "1   2     NaN      NaN  heard about earthquake is different cities sta...   \n",
       "2   3     NaN      NaN  there is  forest fire at spot pond geese are f...   \n",
       "3   9     NaN      NaN              apocalypse lighting spokane wildfires   \n",
       "4  11     NaN      NaN         typhoon soudelor kills in china and taiwan   \n",
       "\n",
       "   special_chars_count              hashtags labels  hashtags_count  \\\n",
       "0                    0                                            0   \n",
       "1                    3          #earthquake                       1   \n",
       "2                    2                                            0   \n",
       "3                    3  #spokane #wildfires                       2   \n",
       "4                    0                                            0   \n",
       "\n",
       "   labels_count  num_chars_count  \\\n",
       "0             0                0   \n",
       "1             0                0   \n",
       "2             0                0   \n",
       "3             0                0   \n",
       "4             0                2   \n",
       "\n",
       "                                          clean_text  text_length  \\\n",
       "0                        happened terrible car crash           33   \n",
       "1  heard earthquake different cities stay safe ev...           61   \n",
       "2  forest fire spot pond geese fleeing across str...           92   \n",
       "3              apocalypse lighting spokane wildfires           37   \n",
       "4                typhoon soudelor kills china taiwan           42   \n",
       "\n",
       "   words_count  vowels_count  short_words_count  stopwords_count  \n",
       "0            6             9                  1                1  \n",
       "1            9            24                  1                2  \n",
       "2           19            29                  5                7  \n",
       "3            4            12                  0                0  \n",
       "4            7            14                  2                2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"special_chars_count\"] =  test[\"text\"]\n",
    "test[\"special_chars_count\"] =  test[\"special_chars_count\"].str.lower()\n",
    "test[\"special_chars_count\"] = test[\"special_chars_count\"].apply(lambda x: re.sub(r'[a-z]','',x))\n",
    "test[\"special_chars_count\"] = test[\"special_chars_count\"].str.strip()\n",
    "test[\"special_chars_count\"] = test[\"special_chars_count\"].apply(lambda x: re.sub(' +','', x))\n",
    "test[\"special_chars_count\"] = test[\"special_chars_count\"].apply(lambda x: re.sub(r'[0-9]','', x))\n",
    "test[\"special_chars_count\"] = test[\"special_chars_count\"].str.len()\n",
    "\n",
    "test[\"hashtags\"] = test[\"text\"].str.lower().str.split(' ').apply(lambda x: concatenate(x,'#'))\n",
    "test[\"labels\"] = test[\"text\"].str.lower().str.split(' ').apply(lambda x: concatenate(x,'@'))\n",
    "test[\"hashtags_count\"] = test[\"hashtags\"].str.split(' ').apply(lambda x: len(x))-1\n",
    "test[\"labels_count\"] = test[\"labels\"].str.split(' ').apply(lambda x: len(x))-1\n",
    "\n",
    "test[\"num_chars_count\"] = test[\"text\"]\n",
    "test[\"num_chars_count\"] =  test[\"num_chars_count\"].str.lower()\n",
    "test[\"num_chars_count\"] = test[\"num_chars_count\"].apply(lambda x: re.sub(r'[a-z]','',x))\n",
    "test[\"num_chars_count\"] = test[\"num_chars_count\"].apply(lambda x: re.sub(r'[^\\w]','',x))\n",
    "test[\"num_chars_count\"] = test[\"num_chars_count\"].str.strip()\n",
    "test[\"num_chars_count\"] = test[\"num_chars_count\"].str.len()\n",
    "\n",
    "test[\"clean_text\"] = test[\"text\"].apply(lambda x: cleaning_text(x))\n",
    "\n",
    "test[\"text\"] = test[\"text\"].str.lower()\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: re.sub('(?P<url>https?://[^\\s]+)', ' ', x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: re.sub(r'_', ' ', x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: re.sub(r'[0-9]',' ', x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: re.sub(' +',' ', x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: re.sub(r'\\b\\w{1}\\b', '', x))\n",
    "test[\"text\"] = test[\"text\"].apply(lambda x: unidecode.unidecode(x))\n",
    "test[\"text\"] = test[\"text\"].str.strip()\n",
    "test[\"text_length\"] = test[\"text\"].str.len()\n",
    "test[\"words_count\"] = test[\"text\"].str.split(' ').apply(lambda x: len(x))\n",
    "\n",
    "test[\"keyword\"] = test[\"keyword\"].str.replace('%20',' ')\n",
    "\n",
    "test[\"vowels_count\"] = test[\"text\"].apply(lambda x: count_vowels(x))\n",
    "test[\"short_words_count\"] = test[\"text\"].apply(lambda x: count_short_words(x))\n",
    "test[\"stopwords_count\"] = test[\"text\"].apply(lambda x: count_stopwords(x))\n",
    "\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete stopwords\n",
    "stopwordsset = set(stopwords.words('english'))\n",
    "stopwordsset.update(['im', 'like', 'get'])\n",
    "train['text'] = train['text'].map(lambda x: ' '.join([word for word in x.split(' ') if word not in stopwordsset])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete stopwords\n",
    "stopwordsset = set(stopwords.words('english'))\n",
    "stopwordsset.update(['im', 'like', 'get'])\n",
    "test['text'] = test['text'].map(lambda x: ' '.join([word for word in x.split(' ') if word not in stopwordsset])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if after deleting empty unsignificant words text become empty replace it with empty placeholder\n",
    "train.loc[train.text=='',\"text\"] = \"emptyplaceholder\"\n",
    "test.loc[test.text=='',\"text\"] = \"emptyplaceholder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>words_count</th>\n",
       "      <th>vowels_count</th>\n",
       "      <th>short_words_count</th>\n",
       "      <th>stopwords_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>earthquake safety los angeles uo safety fasten...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>earthquake safety los angeles uo safety fasten...</td>\n",
       "      <td>54</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm in ri worse than last hurricane my city ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>storm ri worse last hurricane city others hard...</td>\n",
       "      <td>129</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>green line derailment in chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>green line derailment chicago</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meg issues hazardous weather outlook hwo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>meg issues hazardous weather outlook hwo</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cityofcalgary has activated its municipal emer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>#cityofcalgary #yycstorm</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cityofcalgary activated municipal emergency pl...</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10876 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     our deeds are the reason of this earthquake ma...     1.0   \n",
       "1                 forest fire near la ronge sask canada     1.0   \n",
       "2     all residents asked to shelter in place are be...     1.0   \n",
       "3     people receive wildfires evacuation orders in ...     1.0   \n",
       "4     just got sent this photo from ruby alaska as s...     1.0   \n",
       "...                                                 ...     ...   \n",
       "3258  earthquake safety los angeles uo safety fasten...     NaN   \n",
       "3259  storm in ri worse than last hurricane my city ...     NaN   \n",
       "3260                   green line derailment in chicago     NaN   \n",
       "3261           meg issues hazardous weather outlook hwo     NaN   \n",
       "3262  cityofcalgary has activated its municipal emer...     NaN   \n",
       "\n",
       "      special_chars_count                   hashtags labels  hashtags_count  \\\n",
       "0                       1               #earthquake                       1   \n",
       "1                       1                                                 0   \n",
       "2                       3                                                 0   \n",
       "3                       2                #wildfires                       1   \n",
       "4                       2        #alaska #wildfires                       2   \n",
       "...                   ...                        ...    ...             ...   \n",
       "3258                    3                                                 0   \n",
       "3259                    5                                                 0   \n",
       "3260                    5                                                 0   \n",
       "3261                    7                                                 0   \n",
       "3262                    3  #cityofcalgary #yycstorm                       2   \n",
       "\n",
       "      labels_count  num_chars_count  \\\n",
       "0                0                0   \n",
       "1                0                0   \n",
       "2                0                0   \n",
       "3                0                5   \n",
       "4                0                0   \n",
       "...            ...              ...   \n",
       "3258             0                2   \n",
       "3259             0                6   \n",
       "3260             0                0   \n",
       "3261             0                3   \n",
       "3262             0                0   \n",
       "\n",
       "                                             clean_text  text_length  \\\n",
       "0          deeds reason earthquake may allah forgive us           68   \n",
       "1                 forest fire near la ronge sask canada           37   \n",
       "2     residents asked shelter place notified officer...          130   \n",
       "3     people receive wildfires evacuation orders cal...           56   \n",
       "4     got sent photo ruby alaska smoke wildfires pou...           84   \n",
       "...                                                 ...          ...   \n",
       "3258  earthquake safety los angeles uo safety fasten...           54   \n",
       "3259  storm ri worse last hurricane city others hard...          129   \n",
       "3260                      green line derailment chicago           32   \n",
       "3261           meg issues hazardous weather outlook hwo           40   \n",
       "3262  cityofcalgary activated municipal emergency pl...           65   \n",
       "\n",
       "      words_count  vowels_count  short_words_count  stopwords_count  \n",
       "0              13            25                  7                6  \n",
       "1               7            13                  1                0  \n",
       "2              22            45                  9               11  \n",
       "3               7            24                  1                1  \n",
       "4              16            24                  2                6  \n",
       "...           ...           ...                ...              ...  \n",
       "3258            8            18                  2                0  \n",
       "3259           25            36                  8                6  \n",
       "3260            5            12                  1                1  \n",
       "3261            6            16                  2                0  \n",
       "3262            8            19                  2                2  \n",
       "\n",
       "[10876 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.concat([train, test], sort=False)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>keyword_0</th>\n",
       "      <th>keyword_1</th>\n",
       "      <th>keyword_2</th>\n",
       "      <th>keyword_3</th>\n",
       "      <th>keyword_4</th>\n",
       "      <th>keyword_5</th>\n",
       "      <th>keyword_6</th>\n",
       "      <th>keyword_7</th>\n",
       "      <th>keyword_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>earthquake safety los angeles uo safety fasten...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>storm in ri worse than last hurricane my city ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>green line derailment in chicago</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meg issues hazardous weather outlook hwo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cityofcalgary has activated its municipal emer...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>#cityofcalgary #yycstorm</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10876 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \\\n",
       "0     our deeds are the reason of this earthquake ma...     1.0   \n",
       "1                 forest fire near la ronge sask canada     1.0   \n",
       "2     all residents asked to shelter in place are be...     1.0   \n",
       "3     people receive wildfires evacuation orders in ...     1.0   \n",
       "4     just got sent this photo from ruby alaska as s...     1.0   \n",
       "...                                                 ...     ...   \n",
       "3258  earthquake safety los angeles uo safety fasten...     NaN   \n",
       "3259  storm in ri worse than last hurricane my city ...     NaN   \n",
       "3260                   green line derailment in chicago     NaN   \n",
       "3261           meg issues hazardous weather outlook hwo     NaN   \n",
       "3262  cityofcalgary has activated its municipal emer...     NaN   \n",
       "\n",
       "      special_chars_count                   hashtags labels  hashtags_count  \\\n",
       "0                       1               #earthquake                       1   \n",
       "1                       1                                                 0   \n",
       "2                       3                                                 0   \n",
       "3                       2                #wildfires                       1   \n",
       "4                       2        #alaska #wildfires                       2   \n",
       "...                   ...                        ...    ...             ...   \n",
       "3258                    3                                                 0   \n",
       "3259                    5                                                 0   \n",
       "3260                    5                                                 0   \n",
       "3261                    7                                                 0   \n",
       "3262                    3  #cityofcalgary #yycstorm                       2   \n",
       "\n",
       "      labels_count  ...  stopwords_count keyword_0  keyword_1  keyword_2  \\\n",
       "0                0  ...                6         0          0          0   \n",
       "1                0  ...                0         0          0          0   \n",
       "2                0  ...               11         0          0          0   \n",
       "3                0  ...                1         0          0          0   \n",
       "4                0  ...                6         0          0          0   \n",
       "...            ...  ...              ...       ...        ...        ...   \n",
       "3258             0  ...                0         0          0          0   \n",
       "3259             0  ...                6         0          0          0   \n",
       "3260             0  ...                1         0          0          0   \n",
       "3261             0  ...                0         0          0          0   \n",
       "3262             0  ...                2         0          0          0   \n",
       "\n",
       "      keyword_3  keyword_4  keyword_5  keyword_6  keyword_7  keyword_8  \n",
       "0             0          0          0          0          0          1  \n",
       "1             0          0          0          0          0          1  \n",
       "2             0          0          0          0          0          1  \n",
       "3             0          0          0          0          0          1  \n",
       "4             0          0          0          0          0          1  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "3258          0          0          0          0          0          1  \n",
       "3259          0          0          0          0          0          1  \n",
       "3260          0          0          0          0          0          1  \n",
       "3261          0          0          0          0          0          1  \n",
       "3262          0          0          0          0          0          1  \n",
       "\n",
       "[10876 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = ce.BinaryEncoder(cols=['keyword'])\n",
    "tweetsbin = encoder.fit_transform(tweets['keyword'])\n",
    "binary = pd.concat([tweets, tweetsbin], axis=1)\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize the text\n",
    "vectorizer = CountVectorizer(stop_words='english', min_df=20)\n",
    "df_text = tweets[\"text\"]\n",
    "X = vectorizer.fit_transform(df_text)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "951"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_words = vectorizer.get_feature_names()\n",
    "len(feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abc</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accident</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>added</th>\n",
       "      <th>affected</th>\n",
       "      <th>aftershock</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abc  ablaze  absolutely  accident  action  actually  added  affected  \\\n",
       "0    0    0       0           0         0       0         0      0         0   \n",
       "1    0    0       0           0         0       0         0      0         0   \n",
       "2    0    0       0           0         0       0         0      0         0   \n",
       "3    0    0       0           0         0       0         0      0         0   \n",
       "4    0    0       0           0         0       0         0      0         0   \n",
       "\n",
       "   aftershock  ...  year  years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0           0  ...     0      0    0          0     0      0      0        0   \n",
       "1           0  ...     0      0    0          0     0      0      0        0   \n",
       "2           0  ...     0      0    0          0     0      0      0        0   \n",
       "3           0  ...     0      0    0          0     0      0      0        0   \n",
       "4           0  ...     0      0    0          0     0      0      0        0   \n",
       "\n",
       "   yr  zone  \n",
       "0   0     0  \n",
       "1   0     0  \n",
       "2   0     0  \n",
       "3   0     0  \n",
       "4   0     0  \n",
       "\n",
       "[5 rows x 951 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow = pd.DataFrame(X.toarray(), columns=feature_words)\n",
    "df_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0     1.0                    1         #earthquake                       1   \n",
       "1     1.0                    1                                           0   \n",
       "2     1.0                    3                                           0   \n",
       "3     1.0                    2          #wildfires                       1   \n",
       "4     1.0                    2  #alaska #wildfires                       2   \n",
       "\n",
       "   labels_count  ...  year years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0             0  ...     0     0    0          0     0      0      0        0   \n",
       "1             0  ...     0     0    0          0     0      0      0        0   \n",
       "2             0  ...     0     0    0          0     0      0      0        0   \n",
       "3             0  ...     0     0    0          0     0      0      0        0   \n",
       "4             0  ...     0     0    0          0     0      0      0        0   \n",
       "\n",
       "   yr  zone  \n",
       "0   0     0  \n",
       "1   0     0  \n",
       "2   0     0  \n",
       "3   0     0  \n",
       "4   0     0  \n",
       "\n",
       "[5 rows x 977 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINARY_BOW = pd.concat([binary, df_bow.reindex(binary.index)], axis=1)\n",
    "BINARY_BOW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0     1.0                    1         #earthquake                       1   \n",
       "1     1.0                    1                                           0   \n",
       "2     1.0                    3                                           0   \n",
       "3     1.0                    2          #wildfires                       1   \n",
       "4     1.0                    2  #alaska #wildfires                       2   \n",
       "\n",
       "   labels_count  ...  year years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0             0  ...     0     0    0          0     0      0      0        0   \n",
       "1             0  ...     0     0    0          0     0      0      0        0   \n",
       "2             0  ...     0     0    0          0     0      0      0        0   \n",
       "3             0  ...     0     0    0          0     0      0      0        0   \n",
       "4             0  ...     0     0    0          0     0      0      0        0   \n",
       "\n",
       "   yr  zone  \n",
       "0   0     0  \n",
       "1   0     0  \n",
       "2   0     0  \n",
       "3   0     0  \n",
       "4   0     0  \n",
       "\n",
       "[5 rows x 977 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINARY_BOW_TRAIN = BINARY_BOW.loc[BINARY_BOW['target'].notnull(),:]\n",
    "BINARY_BOW_TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened  terrible car crash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is  forest fire at spot pond geese are f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>#spokane #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                  just happened  terrible car crash   \n",
       "1   2     NaN      NaN  heard about earthquake is different cities sta...   \n",
       "2   3     NaN      NaN  there is  forest fire at spot pond geese are f...   \n",
       "3   9     NaN      NaN              apocalypse lighting spokane wildfires   \n",
       "4  11     NaN      NaN         typhoon soudelor kills in china and taiwan   \n",
       "\n",
       "   target  special_chars_count              hashtags labels  hashtags_count  \\\n",
       "0     NaN                    0                                            0   \n",
       "1     NaN                    3          #earthquake                       1   \n",
       "2     NaN                    2                                            0   \n",
       "3     NaN                    3  #spokane #wildfires                       2   \n",
       "4     NaN                    0                                            0   \n",
       "\n",
       "   labels_count  ...  year years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0             0  ...     0     0    0          0     0      0      0        0   \n",
       "1             0  ...     0     0    0          0     0      0      0        0   \n",
       "2             0  ...     0     0    0          0     0      0      0        0   \n",
       "3             0  ...     0     0    0          0     0      0      0        0   \n",
       "4             0  ...     0     0    0          0     0      0      0        0   \n",
       "\n",
       "   yr  zone  \n",
       "0   0     0  \n",
       "1   0     0  \n",
       "2   0     0  \n",
       "3   0     0  \n",
       "4   0     0  \n",
       "\n",
       "[5 rows x 977 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINARY_BOW_TEST = BINARY_BOW.loc[BINARY_BOW['target'].isnull(),:]\n",
    "BINARY_BOW_TEST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = BINARY_BOW_TRAIN.drop([\"id\",\"location\",\"text\",\"target\", \"keyword\",\"hashtags\", \"clean_text\", \"labels\"], axis=1)\n",
    "target2 = BINARY_BOW_TRAIN[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggleId = BINARY_BOW_TEST.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = BINARY_BOW_TEST.drop([\"id\",\"location\",\"text\", \"target\",\"hashtags\", \"clean_text\", \"labels\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data2, target2, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=20)\n",
    "df_text = tweets[\"text\"]\n",
    "text_vector = vectorizer.fit_transform(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aba</th>\n",
       "      <th>abc</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accident</th>\n",
       "      <th>action</th>\n",
       "      <th>actually</th>\n",
       "      <th>added</th>\n",
       "      <th>affected</th>\n",
       "      <th>aftershock</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 951 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aba  abc  ablaze  absolutely  accident  action  actually  added  affected  \\\n",
       "0  0.0  0.0     0.0         0.0       0.0     0.0       0.0    0.0       0.0   \n",
       "1  0.0  0.0     0.0         0.0       0.0     0.0       0.0    0.0       0.0   \n",
       "2  0.0  0.0     0.0         0.0       0.0     0.0       0.0    0.0       0.0   \n",
       "3  0.0  0.0     0.0         0.0       0.0     0.0       0.0    0.0       0.0   \n",
       "4  0.0  0.0     0.0         0.0       0.0     0.0       0.0    0.0       0.0   \n",
       "\n",
       "   aftershock  ...  year  years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0         0.0  ...   0.0    0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "1         0.0  ...   0.0    0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "2         0.0  ...   0.0    0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "3         0.0  ...   0.0    0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "4         0.0  ...   0.0    0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "\n",
       "    yr  zone  \n",
       "0  0.0   0.0  \n",
       "1  0.0   0.0  \n",
       "2  0.0   0.0  \n",
       "3  0.0   0.0  \n",
       "4  0.0   0.0  \n",
       "\n",
       "[5 rows x 951 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_words = vectorizer.get_feature_names()\n",
    "df_tfidf = pd.DataFrame(text_vector.toarray(), columns=feature_words)\n",
    "df_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0     1.0                    1         #earthquake                       1   \n",
       "1     1.0                    1                                           0   \n",
       "2     1.0                    3                                           0   \n",
       "3     1.0                    2          #wildfires                       1   \n",
       "4     1.0                    2  #alaska #wildfires                       2   \n",
       "\n",
       "   labels_count  ...  year years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "1             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "2             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "3             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "4             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "\n",
       "    yr  zone  \n",
       "0  0.0   0.0  \n",
       "1  0.0   0.0  \n",
       "2  0.0   0.0  \n",
       "3  0.0   0.0  \n",
       "4  0.0   0.0  \n",
       "\n",
       "[5 rows x 977 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINARY_TFIDF = pd.concat([binary, df_tfidf.reindex(binary.index)], axis=1)\n",
    "BINARY_TFIDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0     1.0                    1         #earthquake                       1   \n",
       "1     1.0                    1                                           0   \n",
       "2     1.0                    3                                           0   \n",
       "3     1.0                    2          #wildfires                       1   \n",
       "4     1.0                    2  #alaska #wildfires                       2   \n",
       "\n",
       "   labels_count  ...  year years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "1             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "2             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "3             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "4             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "\n",
       "    yr  zone  \n",
       "0  0.0   0.0  \n",
       "1  0.0   0.0  \n",
       "2  0.0   0.0  \n",
       "3  0.0   0.0  \n",
       "4  0.0   0.0  \n",
       "\n",
       "[5 rows x 977 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINARY_TFIDF_TRAIN = BINARY_TFIDF.loc[BINARY_TFIDF['target'].notnull(),:]\n",
    "BINARY_TFIDF_TRAIN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yr</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened  terrible car crash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is  forest fire at spot pond geese are f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>#spokane #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                  just happened  terrible car crash   \n",
       "1   2     NaN      NaN  heard about earthquake is different cities sta...   \n",
       "2   3     NaN      NaN  there is  forest fire at spot pond geese are f...   \n",
       "3   9     NaN      NaN              apocalypse lighting spokane wildfires   \n",
       "4  11     NaN      NaN         typhoon soudelor kills in china and taiwan   \n",
       "\n",
       "   target  special_chars_count              hashtags labels  hashtags_count  \\\n",
       "0     NaN                    0                                            0   \n",
       "1     NaN                    3          #earthquake                       1   \n",
       "2     NaN                    2                                            0   \n",
       "3     NaN                    3  #spokane #wildfires                       2   \n",
       "4     NaN                    0                                            0   \n",
       "\n",
       "   labels_count  ...  year years  yes  yesterday  york  young  youth  youtube  \\\n",
       "0             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "1             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "2             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "3             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "4             0  ...   0.0   0.0  0.0        0.0   0.0    0.0    0.0      0.0   \n",
       "\n",
       "    yr  zone  \n",
       "0  0.0   0.0  \n",
       "1  0.0   0.0  \n",
       "2  0.0   0.0  \n",
       "3  0.0   0.0  \n",
       "4  0.0   0.0  \n",
       "\n",
       "[5 rows x 977 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BINARY_TFIDF_TEST = BINARY_TFIDF.loc[BINARY_TFIDF['target'].isnull(),:]\n",
    "BINARY_TFIDF_TEST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = BINARY_TFIDF_TRAIN.drop([\"id\",\"location\",\"text\",\"target\", \"keyword\",\"hashtags\", \"clean_text\", \"labels\"], axis=1)\n",
    "target3 = BINARY_TFIDF_TRAIN[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test2 = BINARY_TFIDF_TEST.drop([\"id\",\"location\",\"text\", \"target\",\"hashtags\", \"clean_text\", \"labels\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(data3, target3, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(x_train, y_train, x_test):\n",
    "    fs = SelectKBest(score_func=chi2, k=6)\n",
    "    fs.fit(x_train, y_train)\n",
    "    x_train_fs = fs.transform(x_train)\n",
    "    x_test_fs = fs.transform(x_test)\n",
    "    return x_train_fs, x_test_fs, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fs, x_test_fs, fs = select_features(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 623.193571\n",
      "Feature 1: 0.672913\n",
      "Feature 2: nan\n",
      "Feature 3: 0.262745\n",
      "Feature 4: 8.226638\n",
      "Feature 5: 8.984080\n",
      "Feature 6: 7.987866\n",
      "Feature 7: 8.132898\n",
      "Feature 8: 12.413415\n",
      "Feature 9: 0.121415\n",
      "Feature 10: 0.085737\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features2(x_train, y_train, x_test):\n",
    "    fs2 = SelectKBest(score_func=mutual_info_classif, k=6)\n",
    "    fs2.fit(x_train, y_train)\n",
    "    x_train_fs2 = fs2.transform(x_train)\n",
    "    x_test_fs2 = fs2.transform(x_test)\n",
    "    return x_train_fs2, x_test_fs2, fs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_fs2, x_test_fs2, fs2 = select_features2(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.010752\n",
      "Feature 1: 0.007353\n",
      "Feature 2: 0.000000\n",
      "Feature 3: 0.000196\n",
      "Feature 4: 0.006836\n",
      "Feature 5: 0.003373\n",
      "Feature 6: 0.000000\n",
      "Feature 7: 0.018432\n",
      "Feature 8: 0.000000\n",
      "Feature 9: 0.007171\n",
      "Feature 10: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# what are scores for the features\n",
    "for i in range(len(fs2.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs2.scores_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs2.scores_))], fs2.scores_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.03\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(x_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.93\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train_fs, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(x_test_fs)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.66\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(x_train_fs2, y_train)\n",
    "# evaluate the model\n",
    "yhat = model.predict(x_test_fs2)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid_param = {'solver': ['liblinear'],\n",
    "               'penalty': ['l1', 'l2'],\n",
    "                \"C\": np.logspace(-4, 4, 20)}\n",
    "# tuned hpyerparameters :(best parameters)  {'C': 0.012742749857031334, 'penalty': 'l2', 'solver': 'liblinear'}\n",
    "# accuracy : 0.5238363753376147\n",
    "\n",
    "\n",
    "#log_reg_grid_param = {'solver': ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "#                \"C\": np.logspace(-4, 4, 20)}\n",
    "# tuned hpyerparameters :(best parameters)  {'C': 206.913808111479, 'solver': 'liblinear'}\n",
    "# accuracy : 0.6762867722923174\n",
    "\n",
    "#log_reg_grid_param = {'penalty': ['l1', 'l2'],\n",
    "#                \"C\": np.logspace(-4, 4, 20)}\n",
    "# tuned hpyerparameters :(best parameters)  {'C': 11.288378916846883, 'penalty': 'l1'}\n",
    "# accuracy : 0.6773280120566767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticReggesion = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.012742749857031334, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "accuracy : 0.5238363753376147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    3.5s finished\n"
     ]
    }
   ],
   "source": [
    "logistic_GS = GridSearchCV(estimator=logisticReggesion, param_grid=log_reg_grid_param, verbose=1, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "logistic_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logistic_GS.best_params_)\n",
    "print(\"accuracy :\",logistic_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_grid_param2 = {'solver': ['liblinear'],\n",
    "               'penalty': ['l1', 'l2'],\n",
    "                \"C\": np.logspace(-4, 4, 20)}\n",
    "# tuned hpyerparameters :(best parameters)  {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'liblinear'}\n",
    "# accuracy : 0.7345377363929668\n",
    "\n",
    "\n",
    "log_reg_grid_param = {'solver': ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "                    \"C\": np.logspace(-4, 4, 20)}\n",
    "# tuned hpyerparameters :(best parameters)  {'C': 0.615848211066026, 'solver': 'liblinear'}\n",
    "# accuracy : 0.7332050067780481\n",
    "\n",
    "#log_reg_grid_param = {'penalty': ['l1', 'l2'],\n",
    "#                \"C\": np.logspace(-4, 4, 20)}\n",
    "# tuned hpyerparameters :(best parameters)  {'C': 11.288378916846883, 'penalty': 'l1'}\n",
    "# accuracy : 0.6773280120566767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticReggesion2 = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    6.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "accuracy : 0.7345377363929668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    6.9s finished\n"
     ]
    }
   ],
   "source": [
    "logistic_GS2 = GridSearchCV(estimator=logisticReggesion2, param_grid=log_reg_grid_param2, verbose=1, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "logistic_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logistic_GS2.best_params_)\n",
    "print(\"accuracy :\",logistic_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_GS2_predict = logistic_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_logistic_GS2_submit = {'id': kaggleId, 'target': logistic_GS2_predict}\n",
    "kaggle_logistic_GS2_submit_DF = pd.DataFrame(data=kaggle_logistic_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_logistic_GS2_submit_DF.to_csv('setSubmitLogistic.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_param = {'n_neighbors': [3,5,11,19],\n",
    "#               'algorithm': ['auto'],\n",
    "#               'metric': ['manhattan', 'euclidean'],\n",
    "#                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
    "# accuracy : 0.5584487464918637\n",
    "\n",
    "#knn_grid_param = {'n_neighbors': [11,19,25,30],\n",
    "#               'algorithm': ['auto'],\n",
    "#               'metric': ['manhattan', 'euclidean'],\n",
    "#                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 19, 'weights': 'distance'}\n",
    "# accuracy : 0.5584487464918637\n",
    "\n",
    "#knn_grid_param = {'n_neighbors': [14,15,16,17,18,19,20],\n",
    "#               'algorithm': ['auto'],\n",
    "#               'metric': ['manhattan', 'euclidean'],\n",
    "#                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'distance'}\n",
    "# accuracy : 0.5602674085086873\n",
    "\n",
    "knn_grid_param = {'n_neighbors': [3,7,15,50,100,150,200],\n",
    "               'algorithm': ['auto'],\n",
    "               'metric': ['manhattan', 'euclidean'],\n",
    "                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 50, 'weights': 'distance'}\n",
    "# accuracy : 0.5860598980781437"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClassifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "accuracy : 0.5860598980781437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    3.4s finished\n"
     ]
    }
   ],
   "source": [
    "knn_GS = GridSearchCV(estimator=knnClassifier, param_grid=knn_grid_param, verbose=1, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "knn_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",knn_GS.best_params_)\n",
    "print(\"accuracy :\",knn_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_grid_param2 = {'n_neighbors': [3,5,10,15],\n",
    "#               'algorithm': ['auto'],\n",
    "#               'metric': ['manhattan', 'euclidean'],\n",
    "#                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
    "# accuracy : 0.5189932870856757\n",
    "\n",
    "knn_grid_param2 = {'n_neighbors': [2,3,4,10,30,70],\n",
    "               'algorithm': ['auto'],\n",
    "               'metric': ['manhattan', 'euclidean'],\n",
    "                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n",
    "# accuracy : 0.5322323330364732\n",
    "\n",
    "#knn_grid_param = {'n_neighbors': [14,15,16,17,18,19,20],\n",
    "#               'algorithm': ['auto'],\n",
    "#               'metric': ['manhattan', 'euclidean'],\n",
    "#                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'distance'}\n",
    "# accuracy : 0.5602674085086873\n",
    "\n",
    "#knn_grid_param = {'n_neighbors': [17,50,100,150,200],\n",
    "#               'algorithm': ['auto'],\n",
    "#               'metric': ['manhattan', 'euclidean'],\n",
    "#                'weights': ['uniform', 'distance']}\n",
    "# tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 17, 'weights': 'distance'}\n",
    "# accuracy : 0.5602674085086873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnClassifier2 = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 2, 'weights': 'distance'}\n",
      "accuracy : 0.5322323330364732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:   31.6s finished\n"
     ]
    }
   ],
   "source": [
    "knn_GS2 = GridSearchCV(estimator=knnClassifier2, param_grid=knn_grid_param2, verbose=1, scoring=\"f1\", cv=5, n_jobs=-1)\n",
    "knn_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",knn_GS2.best_params_)\n",
    "print(\"accuracy :\",knn_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_GS2_predict = knn_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_knn_GS2_submit = {'id': kaggleId, 'target': knn_GS2_predict}\n",
    "kaggle_knn_GS2_submit_DF = pd.DataFrame(data=kaggle_knn_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_knn_GS2_submit_DF.to_csv('setSubmitKNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_grid = {'max_depth': [20,40,60,80,100],\n",
    "                     'min_samples_split': [2,4,6,8,10],\n",
    "                     'min_samples_leaf': [1,2,5,10]}\n",
    "# tuned hpyerparameters :(best parameters)  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "# accuracy : 0.5658834497487223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionClassifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "accuracy : 0.5658834497487223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "decision_GS = GridSearchCV(estimator=decisionClassifier, param_grid=decision_tree_grid, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "decision_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",decision_GS.best_params_)\n",
    "print(\"accuracy :\",decision_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision_tree_grid2 = {'max_depth': [20,40,60,80,100],\n",
    "#                     'min_samples_split': [2,4,6,8,10],\n",
    "#                     'min_samples_leaf': [1,2,5,10]}\n",
    "# tuned hpyerparameters :(best parameters)  {'max_depth': 100, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
    "# accuracy : 0.6500121884229279\n",
    "\n",
    "#decision_tree_grid2 = {'max_depth': [90,100,150,200],\n",
    "#                     'min_samples_split': [8,10,12,15],\n",
    "#                     'min_samples_leaf': [1,2,3]}\n",
    "# tuned hpyerparameters :(best parameters)  {'max_depth': 150, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
    "# accuracy : 0.6560101863933094\n",
    "\n",
    "decision_tree_grid2 = {'max_depth': [140,150,160],\n",
    "                     'min_samples_split': [8,9,10,11],\n",
    "                     'min_samples_leaf': [1,2,3]}\n",
    "# tuned hpyerparameters :(best parameters)  {'max_depth': 140, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
    "# accuracy : 0.6652465246582776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisionClassifier2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   26.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'max_depth': 140, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "accuracy : 0.6652465246582776\n"
     ]
    }
   ],
   "source": [
    "decision_GS2 = GridSearchCV(estimator=decisionClassifier2, param_grid=decision_tree_grid2, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "decision_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",decision_GS2.best_params_)\n",
    "print(\"accuracy :\",decision_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_GS2_predict = decision_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_decision_GS2_submit = {'id': kaggleId, 'target': decision_GS2_predict}\n",
    "kaggle_decision_GS2_submit_DF = pd.DataFrame(data=kaggle_decision_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_decision_GS2_submit_DF.to_csv('setSubmitDecision.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest_grid_param = {'bootstrap': [True, False],\n",
    "#                            'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#                            'max_features': ['auto', 'sqrt'],\n",
    "#                            'min_samples_leaf': [1, 2, 4],\n",
    "#                            'min_samples_split': [2, 5, 10],\n",
    "#                            'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "#random_forest_grid_param = {'bootstrap': [True, False],\n",
    "#                            'max_depth': [10, 20, 30, None],\n",
    "#                            'max_features': ['auto', 'sqrt'],\n",
    "#                            'min_samples_leaf': [1, 2, 4],\n",
    "#                            'min_samples_split': [2, 5, 10],\n",
    "#                            'n_estimators': [200, 400, 600]}\n",
    "#tuned hpyerparameters :(best parameters)  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "#accuracy : 0.653347094748209\n",
    "\n",
    "#random_forest_grid_param = {'bootstrap': [True],\n",
    "#                            'max_depth': [2, 4, 6, None],\n",
    "#                            'max_features': ['sqrt'],\n",
    "#                            'min_samples_leaf': [1, 5, 7],\n",
    "#                            'min_samples_split': [9, 10, 11],\n",
    "#                            'n_estimators': [50,100,200]}\n",
    "#tuned hpyerparameters :(best parameters)  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
    "#accuracy : 0.6534201199529246\n",
    "\n",
    "random_forest_grid_param = {'bootstrap': [True],\n",
    "                            'max_depth': [2, 4, 6, None],\n",
    "                            'max_features': ['sqrt'],\n",
    "                            'min_samples_leaf': [1,10,15],\n",
    "                            'min_samples_split': [9, 10, 11],\n",
    "                            'n_estimators': [20,30,50,75]}\n",
    "#tuned hpyerparameters :(best parameters)  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 9, 'n_estimators': 20}\n",
    "#accuracy : 0.6541641584525214\n",
    "\n",
    "#random_forest_grid_param = {'bootstrap': [True],\n",
    "#                            'max_depth': [50, 60, 70, None],\n",
    "#                            'max_features': ['sqrt'],\n",
    "#                            'min_samples_leaf': [1,2,3],\n",
    "#                            'min_samples_split': [9, 10, 11],\n",
    "#                            'n_estimators': [5,9,12,15,20]}\n",
    "#tuned hpyerparameters :(best parameters)  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 11, 'n_estimators': 15}\n",
    "#accuracy : 0.6492213934204937"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfClassifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_GS = GridSearchCV(estimator=rfClassifier, param_grid=random_forest_grid_param, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "rf_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",rf_GS.best_params_)\n",
    "print(\"accuracy :\",rf_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_forest_grid_param2 = {'bootstrap': [True, False],\n",
    "#                            'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#                            'max_features': ['auto', 'sqrt'],\n",
    "#                            'min_samples_leaf': [1, 2, 4],\n",
    "#                            'min_samples_split': [2, 5, 10],\n",
    "#                            'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
    "\n",
    "#random_forest_grid_param2 = {'bootstrap': [True, False],\n",
    "#                            'max_depth': [10, 20, 30, None],\n",
    "#                            'max_features': ['auto', 'sqrt'],\n",
    "#                            'min_samples_leaf': [1, 2, 4],\n",
    "#                            'min_samples_split': [2, 5, 10],\n",
    "#                            'n_estimators': [200, 400, 600]}\n",
    "#tuned hpyerparameters :(best parameters)  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', \n",
    "# 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "#accuracy : 0.7212366222022716\n",
    "\n",
    "random_forest_grid_param2 = {'bootstrap': [True],\n",
    "                            'max_depth': [None],\n",
    "                            'max_features': ['sqrt'],\n",
    "                            'min_samples_leaf': [1,2,10],\n",
    "                            'min_samples_split': [10,12,15],\n",
    "                            'n_estimators': [50,100,200]}\n",
    "#tuned hpyerparameters :(best parameters)  {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', \n",
    "#'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}\n",
    "#accuracy : 0.7214048228595785"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfClassifier2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_GS2 = GridSearchCV(estimator=rfClassifier2, param_grid=random_forest_grid_param2, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "rf_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",rf_GS2.best_params_)\n",
    "print(\"accuracy :\",rf_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_GS2_predict = rf_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_rf_GS2_submit = {'id': kaggleId, 'target': rf_GS2_predict}\n",
    "kaggle_rf_GS2_submit_DF = pd.DataFrame(data=kaggle_rf_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_rf_GS2_submit_DF.to_csv('setSubmitRF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid = {'n_estimators': np.arange(280,400,10),\n",
    "            'learning_rate' : [0.01,0.05,0.1,0.3,0.7,1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'learning_rate': 0.7, 'n_estimators': 320}\n",
    "#accuracy : 0.5448198513892962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   46.8s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'learning_rate': 0.7, 'n_estimators': 320}\n",
      "accuracy : 0.5448198513892962\n"
     ]
    }
   ],
   "source": [
    "ada_GS = GridSearchCV(estimator=ada, param_grid=ada_grid, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "ada_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",ada_GS.best_params_)\n",
    "print(\"accuracy :\",ada_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_grid2 = {'n_estimators': np.arange(280,400,10),\n",
    "            'learning_rate' : [0.01,0.1,1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'learning_rate': 1, 'n_estimators': 380}\n",
    "#accuracy : 0.7211916742238501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada2 = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'learning_rate': 1, 'n_estimators': 380}\n",
      "accuracy : 0.7211916742238501\n"
     ]
    }
   ],
   "source": [
    "ada_GS2 = GridSearchCV(estimator=ada2, param_grid=ada_grid2, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "ada_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",ada_GS2.best_params_)\n",
    "print(\"accuracy :\",ada_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_GS2_predict = ada_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_ada_GS2_submit = {'id': kaggleId, 'target': ada_GS2_predict}\n",
    "kaggle_ada_GS2_submit_DF = pd.DataFrame(data=kaggle_ada_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_ada_GS2_submit_DF.to_csv('setSubmitAda.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_grid_param = {\n",
    "#    'max_depth': [5,7,9],\n",
    "#    'gamma': [0.5, 1, 1.5],\n",
    "#    'subsample': [0.4,0.5,0.6], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "#    'min_child_weight': [1,3,4],\n",
    "#    'colsample_bytree': [0.5,0.6,0.7], #[0.5,0.6,0.7,0.8],\n",
    "#    'n_estimators': [100, 200], #[1000,2000,3000]\n",
    "#    'learning_rate': [0.1, 1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.7, 'gamma': 1, 'learning_rate': 0.1, \n",
    "#    'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.5}\n",
    "#accuracy : 0.670547740462945\n",
    "\n",
    "#xgb_grid_param = {\n",
    "#    'max_depth': [9,12],\n",
    "#    'gamma': [0.9,1,1.2],\n",
    "#    'subsample': [0.5,0.8], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "#    'min_child_weight': [1,3,4],\n",
    "#    'colsample_bytree': [0.7,0.9], #[0.5,0.6,0.7,0.8],\n",
    "#    'n_estimators': [200,350], #[1000,2000,3000]\n",
    "#    'learning_rate': [0.1, 0.5]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.9, 'gamma': 1.2, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 350, 'subsample': 0.8}\n",
    "#accuracy : 0.6696604992524797\n",
    "\n",
    "xgb_grid_param = {\n",
    "    'max_depth': [9],\n",
    "    'gamma': [1,1.2],\n",
    "    'subsample': [0.8,1], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    'min_child_weight': [1,2],\n",
    "    'colsample_bytree': [0.7,0.9], #[0.5,0.6,0.7,0.8],\n",
    "    'n_estimators': [600], #[1000,2000,3000]\n",
    "    'learning_rate': [0.1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.9, 'gamma': 1.2, 'learning_rate': 0.1, 'max_depth': 9, 'min_child_weight': 1, 'n_estimators': 600, 'subsample': 0.8}\n",
    "#accuracy : 0.6681432627951468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_GS = GridSearchCV(estimator=xgboost, param_grid=xgb_grid_param, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "xgboost_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",xgboost_GS.best_params_)\n",
    "print(\"accuracy :\",xgboost_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_grid_param2 = {\n",
    "#    'max_depth': [2,3,5,6,10],\n",
    "#    'gamma': [1],\n",
    "#    'subsample': [0.5], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "#    'min_child_weight': [1,2],\n",
    "#    'colsample_bytree': [0.7], #[0.5,0.6,0.7,0.8],\n",
    "#    'n_estimators': [300], #[1000,2000,3000]\n",
    "#    'learning_rate': [1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.7, 'gamma': 1, 'learning_rate': 1, \n",
    "#'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 300, 'subsample': 0.5}\n",
    "#accuracy : 0.6953201310248737\n",
    "\n",
    "#xgb_grid_param2 = {\n",
    "#    'max_depth': [3,4],\n",
    "#    'gamma': [0.7,0.8],\n",
    "#    'subsample': [0.5], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "#    'min_child_weight': [1],\n",
    "#    'colsample_bytree': [0.7], #[0.5,0.6,0.7,0.8],\n",
    "#    'n_estimators': [300], #[1000,2000,3000]\n",
    "#    'learning_rate': [1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.7, 'gamma': 0.8, 'learning_rate': 1, '\n",
    "#max_depth': 3, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.5}\n",
    "#accuracy : 0.6964528252886683\n",
    "\n",
    "#xgb_grid_param2 = {\n",
    "#    'max_depth': [3],\n",
    "#    'gamma': [0.8],\n",
    "#    'subsample': [0.7], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "#    'min_child_weight': [1,2],\n",
    "#    'colsample_bytree': [0.6,0.7,0.8], #[0.5,0.6,0.7,0.8],\n",
    "#    'n_estimators': [300], #[1000,2000,3000]\n",
    "#    'learning_rate': [1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.8, 'gamma': 0.8, 'learning_rate': 1, \n",
    "#'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.7}\n",
    "#accuracy : 0.7115072057243385\n",
    "\n",
    "xgb_grid_param2 = {\n",
    "    'max_depth': [3],\n",
    "    'gamma': [0.8],\n",
    "    'subsample': [0.7], #[0.4,0.5,0.6,0.7,0.8,0.9,1.0],\n",
    "    'min_child_weight': [1],\n",
    "    'colsample_bytree': [0.8], #[0.5,0.6,0.7,0.8],\n",
    "    'n_estimators': [200,300,400], #[1000,2000,3000]\n",
    "    'learning_rate': [0.1,1]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.8, 'gamma': 0.8, 'learning_rate': 1, \n",
    "#'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.7}\n",
    "#accuracy : 0.712881419602948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost2 = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2bd624387112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgboost_GS2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgboost2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_grid_param2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgboost_GS2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tuned hpyerparameters :(best parameters) \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxgboost_GS2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accuracy :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mxgboost_GS2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \"\"\"\n\u001b[1;32m    604\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mcheck_cv\u001b[0;34m(cv, y, classifier)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         if (classifier and (y is not None) and\n\u001b[0;32m-> 1983\u001b[0;31m                 (type_of_target(y) in ('binary', 'multiclass'))):\n\u001b[0m\u001b[1;32m   1984\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'f'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m'continuous'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "xgboost_GS2 = GridSearchCV(estimator=xgboost2, param_grid=xgb_grid_param2, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "xgboost_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",xgboost_GS2.best_params_)\n",
    "print(\"accuracy :\",xgboost_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_GS2_predict = xgboost_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_xgboost_GS2_submit = {'id': kaggleId, 'target': xgboost_GS2_predict}\n",
    "kaggle_xgboost_GS2_submit_DF = pd.DataFrame(data=kaggle_xgboost_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_xgboost_GS2_submit_DF.to_csv('setSubmitXgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sin la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbm_param = {'n_estimators': [100, 400],\n",
    "#               'max_depth':  [-1, 4, 10],\n",
    "#               'num_leaves': [15, 31, 63, 127],\n",
    "#               'subsample': [0.6, 0.7, 0.8],\n",
    "#               'colsample_bytree': [0.6, 0.7, 0.8]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.6, 'max_depth': 10, 'n_estimators': 400, \n",
    "#'num_leaves': 15, 'subsample': 0.6}\n",
    "#accuracy : 0.6008785161044997\n",
    "\n",
    "#gbm_param = {'n_estimators': [400, 600, 1000],\n",
    "#               'max_depth':  [-1, 10, 30],\n",
    "#               'num_leaves': [3,6,9,12,15],\n",
    "#               'subsample': [0.5,0.6, 0.7],\n",
    "#               'colsample_bytree': [0.5,0.6, 0.7]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.6, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 15, 'subsample': 0.5}\n",
    "#accuracy : 0.6040637466465371\n",
    "\n",
    "gbm_param = {'n_estimators': [1000,1500,2000],\n",
    "               'max_depth':  [-1, 10, 30, 50],\n",
    "               'num_leaves': [9,12,15,17,20],\n",
    "               'subsample': [0.3,0.4,0.5,0.6],\n",
    "               'colsample_bytree': [0.5,0.6, 0.7]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.6, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 15, 'subsample': 0.3}\n",
    "#accuracy : 0.6040637466465371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_GS = GridSearchCV(estimator=gbm, param_grid=gbm_param, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "gbm_GS.fit(x_train, y_train)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",gbm_GS.best_params_)\n",
    "print(\"accuracy :\",gbm_GS.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con la columna Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbm_param2 = {'n_estimators': [100, 200],\n",
    "#               'max_depth':  [-1, 4, 10],\n",
    "#               'num_leaves': [15, 31, 63, 127],\n",
    "#               'subsample': [0.6, 0.7, 0.8],\n",
    "#               'colsample_bytree': [0.6, 0.7, 0.8]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.7, 'max_depth': -1, 'n_estimators': 100, \n",
    "#'num_leaves': 63, 'subsample': 0.6}\n",
    "#accuracy : 0.6962262268218196\n",
    "\n",
    "gbm_param2 = {'n_estimators': [50,75,100],\n",
    "               'max_depth':  [-1,2,3],\n",
    "               'num_leaves': [50,60,70],\n",
    "               'subsample': [0.5,0.6,0.7],\n",
    "               'colsample_bytree': [0.6,0.7,0.8]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.8, 'max_depth': -1, 'n_estimators': 75, \n",
    "#'num_leaves': 70, 'subsample': 0.5}\n",
    "#accuracy : 0.6953875796154907\n",
    "\n",
    "#gbm_param = {'n_estimators': [1000,1500,2000],\n",
    "#               'max_depth':  [-1, 10, 30, 50],\n",
    "#               'num_leaves': [9,12,15,17,20],\n",
    "#               'subsample': [0.3,0.4,0.5,0.6],\n",
    "#               'colsample_bytree': [0.5,0.6, 0.7]}\n",
    "#tuned hpyerparameters :(best parameters)  {'colsample_bytree': 0.6, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 15, 'subsample': 0.3}\n",
    "#accuracy : 0.6040637466465371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm2 = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_GS2 = GridSearchCV(estimator=gbm2, param_grid=gbm_param2, scoring='f1', verbose=1, cv=5, n_jobs=-1)\n",
    "gbm_GS2.fit(x_train2, y_train2)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",gbm_GS2.best_params_)\n",
    "print(\"accuracy :\",gbm_GS2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_GS2_predict = gbm_GS2.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_gbm_GS2_submit = {'id': kaggleId, 'target': gbm_GS2_predict}\n",
    "kaggle_gbm_GS2_submit_DF = pd.DataFrame(data=kaggle_gbm_GS2_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_gbm_GS2_submit_DF.to_csv('setSubmitGBM.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
