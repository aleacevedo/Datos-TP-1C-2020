{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import unidecode\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../data/train.csv\")\n",
    "tweets_test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   id           7613 non-null   int64   \n",
      " 1   keyword      7552 non-null   category\n",
      " 2   location     5080 non-null   object  \n",
      " 3   text         7613 non-null   object  \n",
      " 4   target       7613 non-null   int64   \n",
      " 5   text_length  7613 non-null   int64   \n",
      " 6   words_count  7613 non-null   int64   \n",
      "dtypes: category(1), int64(4), object(2)\n",
      "memory usage: 383.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].str.lower()\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub('(?P<url>https?://[^\\s]+)', ' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'_', ' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'[0-9]',' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(' +',' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: unidecode.unidecode(x))\n",
    "tweets[\"text\"] = tweets[\"text\"].str.strip()\n",
    "tweets[\"text_length\"] = tweets[\"text\"].str.len()\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'\\b\\w{1}\\b', '', x))\n",
    "tweets[\"words_count\"] = tweets[\"text\"].str.split(' ').apply(lambda x: len(x))\n",
    "\n",
    "tweets[\"keyword\"] = tweets[\"keyword\"].str.replace('%20',' ')\n",
    "tweets[\"keyword\"] = tweets[\"keyword\"].astype('category')\n",
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_length</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  text_length  words_count  \n",
       "0       1           68           13  \n",
       "1       1           37            7  \n",
       "2       1          130           22  \n",
       "3       1           56            7  \n",
       "4       1           85           16  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   id           3263 non-null   int64   \n",
      " 1   keyword      3237 non-null   category\n",
      " 2   location     2158 non-null   object  \n",
      " 3   text         3263 non-null   object  \n",
      " 4   text_length  3263 non-null   int64   \n",
      " 5   words_count  3263 non-null   int64   \n",
      "dtypes: category(1), int64(3), object(2)\n",
      "memory usage: 145.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tweets_test[\"text\"] = tweets_test[\"text\"].str.lower()\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: re.sub('(?P<url>https?://[^\\s]+)', ' ', x))\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: re.sub(r'_', ' ', x))\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: re.sub(r'[0-9]',' ', x))\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: re.sub(' +',' ', x))\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: unidecode.unidecode(x))\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].str.strip()\n",
    "tweets_test[\"text_length\"] = tweets_test[\"text\"].str.len()\n",
    "tweets_test[\"text\"] = tweets_test[\"text\"].apply(lambda x: re.sub(r'\\b\\w{1}\\b', '', x))\n",
    "tweets_test[\"words_count\"] = tweets_test[\"text\"].str.split(' ').apply(lambda x: len(x))\n",
    "\n",
    "tweets_test[\"keyword\"] = tweets_test[\"keyword\"].str.replace('%20',' ')\n",
    "tweets_test[\"keyword\"] = tweets_test[\"keyword\"].astype('category')\n",
    "tweets_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened  terrible car crash</td>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>61</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is  forest fire at spot pond geese are f...</td>\n",
       "      <td>94</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   0     NaN      NaN                  just happened  terrible car crash   \n",
       "1   2     NaN      NaN  heard about earthquake is different cities sta...   \n",
       "2   3     NaN      NaN  there is  forest fire at spot pond geese are f...   \n",
       "3   9     NaN      NaN              apocalypse lighting spokane wildfires   \n",
       "4  11     NaN      NaN         typhoon soudelor kills in china and taiwan   \n",
       "\n",
       "   text_length  words_count  \n",
       "0           34            6  \n",
       "1           61            9  \n",
       "2           94           19  \n",
       "3           37            4  \n",
       "4           42            7  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 6)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding\n",
    "dummies = pd.get_dummies(tweets[\"keyword\"], prefix=\"keyword\")\n",
    "dummies_test = pd.get_dummies(tweets_test[\"keyword\"], prefix=\"keyword\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'target', 'text_length',\n",
       "       'words_count', 'keyword_ablaze', 'keyword_accident',\n",
       "       'keyword_aftershock',\n",
       "       ...\n",
       "       'keyword_weapons', 'keyword_whirlwind', 'keyword_wild fires',\n",
       "       'keyword_wildfire', 'keyword_windstorm', 'keyword_wounded',\n",
       "       'keyword_wounds', 'keyword_wreck', 'keyword_wreckage',\n",
       "       'keyword_wrecked'],\n",
       "      dtype='object', length=228)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_ohe = pd.concat([tweets,dummies], axis=\"columns\")\n",
    "tweets_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 228)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'text_length', 'words_count',\n",
       "       'keyword_ablaze', 'keyword_accident', 'keyword_aftershock',\n",
       "       'keyword_airplane accident',\n",
       "       ...\n",
       "       'keyword_weapons', 'keyword_whirlwind', 'keyword_wild fires',\n",
       "       'keyword_wildfire', 'keyword_windstorm', 'keyword_wounded',\n",
       "       'keyword_wounds', 'keyword_wreck', 'keyword_wreckage',\n",
       "       'keyword_wrecked'],\n",
       "      dtype='object', length=227)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test_ohe = pd.concat([tweets_test,dummies_test], axis=\"columns\")\n",
    "tweets_test_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 227)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_test_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train-test usando solo tweets\n",
    "X = tweets_ohe.drop([\"id\",\"keyword\",\"location\",\"text\",\"target\"], axis=1)\n",
    "y = tweets_ohe[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 223)\n",
      "(1904, 223)\n",
      "(5709,)\n",
      "(1904,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.75775187\n",
      "Iteration 2, loss = 0.69271912\n",
      "Iteration 3, loss = 0.68979041\n",
      "Iteration 4, loss = 0.68782011\n",
      "Iteration 5, loss = 0.68639433\n",
      "Iteration 6, loss = 0.68450943\n",
      "Iteration 7, loss = 0.68195148\n",
      "Iteration 8, loss = 0.68018310\n",
      "Iteration 9, loss = 0.67861739\n",
      "Iteration 10, loss = 0.67640668\n",
      "Iteration 11, loss = 0.67395115\n",
      "Iteration 12, loss = 0.67062071\n",
      "Iteration 13, loss = 0.66534952\n",
      "Iteration 14, loss = 0.65445171\n",
      "Iteration 15, loss = 0.63414684\n",
      "Iteration 16, loss = 0.61513558\n",
      "Iteration 17, loss = 0.59972799\n",
      "Iteration 18, loss = 0.58514022\n",
      "Iteration 19, loss = 0.56449329\n",
      "Iteration 20, loss = 0.55157997\n",
      "Iteration 21, loss = 0.54418458\n",
      "Iteration 22, loss = 0.53373113\n",
      "Iteration 23, loss = 0.53111442\n",
      "Iteration 24, loss = 0.52603809\n",
      "Iteration 25, loss = 0.51951276\n",
      "Iteration 26, loss = 0.51654164\n",
      "Iteration 27, loss = 0.51730904\n",
      "Iteration 28, loss = 0.52151894\n",
      "Iteration 29, loss = 0.51563074\n",
      "Iteration 30, loss = 0.51266131\n",
      "Iteration 31, loss = 0.51558433\n",
      "Iteration 32, loss = 0.51594579\n",
      "Iteration 33, loss = 0.51392760\n",
      "Iteration 34, loss = 0.51633276\n",
      "Iteration 35, loss = 0.51066935\n",
      "Iteration 36, loss = 0.50977262\n",
      "Iteration 37, loss = 0.50743373\n",
      "Iteration 38, loss = 0.50594575\n",
      "Iteration 39, loss = 0.50814920\n",
      "Iteration 40, loss = 0.52016211\n",
      "Iteration 41, loss = 0.51091676\n",
      "Iteration 42, loss = 0.51070162\n",
      "Iteration 43, loss = 0.50660070\n",
      "Iteration 44, loss = 0.50672396\n",
      "Iteration 45, loss = 0.50625423\n",
      "Iteration 46, loss = 0.50547217\n",
      "Iteration 47, loss = 0.50685642\n",
      "Iteration 48, loss = 0.50989303\n",
      "Iteration 49, loss = 0.50718042\n",
      "Iteration 50, loss = 0.50738979\n",
      "Iteration 51, loss = 0.50599591\n",
      "Iteration 52, loss = 0.50608072\n",
      "Iteration 53, loss = 0.50524264\n",
      "Iteration 54, loss = 0.50868318\n",
      "Iteration 55, loss = 0.50812253\n",
      "Iteration 56, loss = 0.50498623\n",
      "Iteration 57, loss = 0.50477227\n",
      "Iteration 58, loss = 0.51405841\n",
      "Iteration 59, loss = 0.50437308\n",
      "Iteration 60, loss = 0.50795683\n",
      "Iteration 61, loss = 0.50589753\n",
      "Iteration 62, loss = 0.51281206\n",
      "Iteration 63, loss = 0.50474802\n",
      "Iteration 64, loss = 0.50394280\n",
      "Iteration 65, loss = 0.50742379\n",
      "Iteration 66, loss = 0.51371381\n",
      "Iteration 67, loss = 0.50589096\n",
      "Iteration 68, loss = 0.50480826\n",
      "Iteration 69, loss = 0.50572451\n",
      "Iteration 70, loss = 0.50352682\n",
      "Iteration 71, loss = 0.50481277\n",
      "Iteration 72, loss = 0.50335306\n",
      "Iteration 73, loss = 0.50669324\n",
      "Iteration 74, loss = 0.50357321\n",
      "Iteration 75, loss = 0.50432133\n",
      "Iteration 76, loss = 0.50862833\n",
      "Iteration 77, loss = 0.50299064\n",
      "Iteration 78, loss = 0.50977868\n",
      "Iteration 79, loss = 0.50480462\n",
      "Iteration 80, loss = 0.50460737\n",
      "Iteration 81, loss = 0.50275105\n",
      "Iteration 82, loss = 0.50574057\n",
      "Iteration 83, loss = 0.50288261\n",
      "Iteration 84, loss = 0.50251708\n",
      "Iteration 85, loss = 0.50362135\n",
      "Iteration 86, loss = 0.50241356\n",
      "Iteration 87, loss = 0.50267751\n",
      "Iteration 88, loss = 0.50821881\n",
      "Iteration 89, loss = 0.50193107\n",
      "Iteration 90, loss = 0.50317350\n",
      "Iteration 91, loss = 0.50239791\n",
      "Iteration 92, loss = 0.50382956\n",
      "Iteration 93, loss = 0.50262582\n",
      "Iteration 94, loss = 0.50189119\n",
      "Iteration 95, loss = 0.50911969\n",
      "Iteration 96, loss = 0.50286792\n",
      "Iteration 97, loss = 0.50297408\n",
      "Iteration 98, loss = 0.50184262\n",
      "Iteration 99, loss = 0.50135505\n",
      "Iteration 100, loss = 0.50230305\n",
      "Iteration 101, loss = 0.50442581\n",
      "Iteration 102, loss = 0.50211893\n",
      "Iteration 103, loss = 0.50977586\n",
      "Iteration 104, loss = 0.50192463\n",
      "Iteration 105, loss = 0.50437279\n",
      "Iteration 106, loss = 0.50341630\n",
      "Iteration 107, loss = 0.50199246\n",
      "Iteration 108, loss = 0.50542686\n",
      "Iteration 109, loss = 0.50074102\n",
      "Iteration 110, loss = 0.50104563\n",
      "Iteration 111, loss = 0.49981673\n",
      "Iteration 112, loss = 0.50266215\n",
      "Iteration 113, loss = 0.50139337\n",
      "Iteration 114, loss = 0.50194671\n",
      "Iteration 115, loss = 0.50160685\n",
      "Iteration 116, loss = 0.50178033\n",
      "Iteration 117, loss = 0.50367829\n",
      "Iteration 118, loss = 0.50145109\n",
      "Iteration 119, loss = 0.50658957\n",
      "Iteration 120, loss = 0.50144003\n",
      "Iteration 121, loss = 0.50056233\n",
      "Iteration 122, loss = 0.50182054\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(8, 8, 8), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), max_iter=300, verbose=True)\n",
    "model_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.738971\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_mlp.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[824 285]\n",
      " [212 583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77      1109\n",
      "           1       0.67      0.73      0.70       795\n",
      "\n",
      "    accuracy                           0.74      1904\n",
      "   macro avg       0.73      0.74      0.73      1904\n",
      "weighted avg       0.74      0.74      0.74      1904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_test_hat))\n",
    "print(classification_report(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando standard scaler\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tweets_ohe.drop([\"id\",\"keyword\",\"location\",\"text\",\"target\"], axis=1)\n",
    "y_train = tweets_ohe[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = tweets_test_ohe.drop([\"id\",\"keyword\",\"location\",\"text\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLPClassifier(hidden_layer_sizes=(8,8,8), max_iter=300, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 58.859401\n"
     ]
    }
   ],
   "source": [
    "#Usando cross-validation\n",
    "kfold = KFold(n_splits=4, random_state=100)\n",
    "resultados = cross_val_score(model_mlp, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(\"../data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(8, 8, 8), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=300,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission[\"target\"] = model_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43303708243947286"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
