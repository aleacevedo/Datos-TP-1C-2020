{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import unidecode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "test = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):        \n",
    "    clean_word = ''.join([char for char in word if char not in string.punctuation])\n",
    "    return clean_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    text_tokenize = tokenizer.tokenize(text)\n",
    "    wordlist = []\n",
    "    for word in text_tokenize:\n",
    "        word = word.lower()\n",
    "        word = re.sub('(?P<url>https?://[^\\s]+)', ' ', word)\n",
    "        word = remove_punctuation(word)\n",
    "        word = re.sub(r'[^\\w]', ' ', word)\n",
    "        word = unidecode.unidecode(word)\n",
    "        word = re.sub(r'[0-9]','', word)\n",
    "        if((word != '')&(word != ' ')&(word not in stopwords)):\n",
    "            wordlist.append(word)\n",
    "    clean_text = ' '.join(wordlist)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>keyword_original</th>\n",
       "      <th>location_original</th>\n",
       "      <th>text_original</th>\n",
       "      <th>target_label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_original keyword_original location_original  \\\n",
       "0            1              NaN               NaN   \n",
       "1            4              NaN               NaN   \n",
       "2            5              NaN               NaN   \n",
       "3            6              NaN               NaN   \n",
       "4            7              NaN               NaN   \n",
       "\n",
       "                                       text_original  target_label  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...             1   \n",
       "1             Forest fire near La Ronge Sask. Canada             1   \n",
       "2  All residents asked to 'shelter in place' are ...             1   \n",
       "3  13,000 people receive #wildfires evacuation or...             1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...             1   \n",
       "\n",
       "                                          clean_text  \n",
       "0       deeds reason earthquake may allah forgive us  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  residents asked shelter place notified officer...  \n",
       "3  people receive wildfires evacuation orders cal...  \n",
       "4  got sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"clean_text\"] = train[\"text\"].apply(lambda x: cleaning_text(x))\n",
    "train.rename(columns={\"target\":\"target_label\"}, inplace=True)\n",
    "train.rename(columns={\"location\":\"location_original\"}, inplace=True)\n",
    "train.rename(columns={\"id\":\"id_original\"}, inplace=True)\n",
    "train.rename(columns={\"text\":\"text_original\"}, inplace=True)\n",
    "train.rename(columns={\"keyword\":\"keyword_original\"}, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>keyword_original</th>\n",
       "      <th>location_original</th>\n",
       "      <th>text_original</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_original keyword_original location_original  \\\n",
       "0            0              NaN               NaN   \n",
       "1            2              NaN               NaN   \n",
       "2            3              NaN               NaN   \n",
       "3            9              NaN               NaN   \n",
       "4           11              NaN               NaN   \n",
       "\n",
       "                                       text_original  \\\n",
       "0                 Just happened a terrible car crash   \n",
       "1  Heard about #earthquake is different cities, s...   \n",
       "2  there is a forest fire at spot pond, geese are...   \n",
       "3           Apocalypse lighting. #Spokane #wildfires   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "\n",
       "                                          clean_text  \n",
       "0                        happened terrible car crash  \n",
       "1  heard earthquake different cities stay safe ev...  \n",
       "2  forest fire spot pond geese fleeing across str...  \n",
       "3              apocalypse lighting spokane wildfires  \n",
       "4                typhoon soudelor kills china taiwan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"clean_text\"] = test[\"text\"].apply(lambda x: cleaning_text(x))\n",
    "test.rename(columns={\"location\":\"location_original\"}, inplace=True)\n",
    "test.rename(columns={\"id\":\"id_original\"}, inplace=True)\n",
    "test.rename(columns={\"text\":\"text_original\"}, inplace=True)\n",
    "test.rename(columns={\"keyword\":\"keyword_original\"}, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "train_tfidf = vectorizer.fit_transform(train[\"clean_text\"])\n",
    "test_tfidf = vectorizer.transform(test[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_words = vectorizer.get_feature_names()\n",
    "len(feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_tfidf\n",
    "y = train[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 5000)\n",
      "(1904, 5000)\n",
      "(5709,)\n",
      "(1904,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustando hiper-parametros (usando 748 feature-words):\n",
    "    - n_estimators=50, max_depth=11, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=1, alpha=0\n",
    "    SCORE: 0.761029\n",
    "    - n_estimators=50, max_depth=11, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=1, alpha=0\n",
    "    SCORE: 0.767332\n",
    "    - n_estimators=100, max_depth=7, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=1, alpha=0\n",
    "    SCORE: 0.769958\n",
    "    - n_estimators=100, max_depth=11, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=1, alpha=0\n",
    "    SCORE: 0.773634\n",
    "    - n_estimators=100, max_depth=15, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=1, alpha=0\n",
    "    SCORE: 0.773786\n",
    "    - n_estimators=100, max_depth=13, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=0.1, alpha=0\n",
    "    SCORE: 0.777311\n",
    "    - n_estimators=100, max_depth=13, learning_rate=0.1, subsample=1, colsample_bytree=0.3, lambda=0.1, alpha=0\n",
    "    SCORE: 0.775210\n",
    "    - n_estimators=200, max_depth=9, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=0.5, alpha=0\n",
    "    SCORE: 0.777836\n",
    "    - n_estimators=200, max_depth=13, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=0.1, alpha=0\n",
    "    SCORE: 0.783088\n",
    "    - n_estimators=200, max_depth=13, learning_rate=0.1, subsample=1, colsample_bytree=0.7, lambda=0.1, alpha=0\n",
    "    SCORE: 0.787815\n",
    "    - n_estimators=200, max_depth=15, learning_rate=0.1, subsample=1, colsample_bytree=0.5, lambda=0.1, alpha=0\n",
    "    SCORE: 0.785189\n",
    "    - n_estimators=250, max_depth=13 u 11, learning_rate=0.1, subsample=1, colsample_bytree=0.7, lambda=0.1, alpha=0\n",
    "    SCORE: 0.790966\n",
    "    - n_estimators=250, max_depth=11, learning_rate=0.1, subsample=1, colsample_bytree=0.7, lambda=0.1, alpha=0.1\n",
    "    SCORE: 0.789391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=0.1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=250, objective='binary:logistic', max_depth=11, learning_rate=0.1,\n",
    "                          subsample=1, colsample_bytree=0.7, reg_lambda=0.1, n_jobs=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.794118\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.93907563025209"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgb.score(X_test, y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usando kfold y stratified kfold\n",
    "model_xgb = xgb.XGBClassifier(n_estimators=250, objective='binary:logistic', max_depth=11, learning_rate=0.1,\n",
    "                          subsample=1, colsample_bytree=0.5, reg_lambda=0.1, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.773785\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=6, random_state=100)\n",
    "resultados = cross_val_score(model_xgb, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.738903\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=8, random_state=134)\n",
    "resultados = cross_val_score(model_xgb, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=11,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=1, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=0.1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=250, objective='binary:logistic', max_depth=11, learning_rate=0.1,\n",
    "                          subsample=1, colsample_bytree=0.7, reg_lambda=0.1, n_jobs=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_original  target\n",
       "0               0       0\n",
       "1               2       1\n",
       "2               3       1\n",
       "3               9       0\n",
       "4              11       1\n",
       "...           ...     ...\n",
       "3258        10861       1\n",
       "3259        10865       1\n",
       "3260        10868       1\n",
       "3261        10874       1\n",
       "3262        10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"target\"] = y_pred\n",
    "test[[\"id_original\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"id_original\",\"target\"]].rename(columns={\"id_original\":\"id\"}).to_csv(\"../data/pred4_XGB_Tfidf\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
