{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import unidecode\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_binary.csv\")\n",
    "test = pd.read_csv(\"../data/test_binary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>keyword_original</th>\n",
       "      <th>location_original</th>\n",
       "      <th>text_original</th>\n",
       "      <th>target_label</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>...</th>\n",
       "      <th>words_count</th>\n",
       "      <th>keyword_original_0</th>\n",
       "      <th>keyword_original_1</th>\n",
       "      <th>keyword_original_2</th>\n",
       "      <th>keyword_original_3</th>\n",
       "      <th>keyword_original_4</th>\n",
       "      <th>keyword_original_5</th>\n",
       "      <th>keyword_original_6</th>\n",
       "      <th>keyword_original_7</th>\n",
       "      <th>keyword_original_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_original keyword_original location_original  \\\n",
       "0            1              NaN               NaN   \n",
       "1            4              NaN               NaN   \n",
       "2            5              NaN               NaN   \n",
       "3            6              NaN               NaN   \n",
       "4            7              NaN               NaN   \n",
       "\n",
       "                                       text_original  target_label  \\\n",
       "0  our deeds are the reason of this earthquake ma...             1   \n",
       "1              forest fire near la ronge sask canada             1   \n",
       "2  all residents asked to shelter in place are be...             1   \n",
       "3  people receive wildfires evacuation orders in ...             1   \n",
       "4  just got sent this photo from ruby alaska as s...             1   \n",
       "\n",
       "   special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0                    1         #earthquake     NaN               1   \n",
       "1                    1                  NaN    NaN               0   \n",
       "2                    3                  NaN    NaN               0   \n",
       "3                    2          #wildfires     NaN               1   \n",
       "4                    2  #alaska #wildfires     NaN               2   \n",
       "\n",
       "   labels_count  ...  words_count  keyword_original_0 keyword_original_1  \\\n",
       "0             0  ...           13                   0                  0   \n",
       "1             0  ...            7                   0                  0   \n",
       "2             0  ...           22                   0                  0   \n",
       "3             0  ...            7                   0                  0   \n",
       "4             0  ...           16                   0                  0   \n",
       "\n",
       "   keyword_original_2  keyword_original_3  keyword_original_4  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   keyword_original_5  keyword_original_6  keyword_original_7  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   keyword_original_8  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>keyword_original</th>\n",
       "      <th>location_original</th>\n",
       "      <th>text_original</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>...</th>\n",
       "      <th>words_count</th>\n",
       "      <th>keyword_original_0</th>\n",
       "      <th>keyword_original_1</th>\n",
       "      <th>keyword_original_2</th>\n",
       "      <th>keyword_original_3</th>\n",
       "      <th>keyword_original_4</th>\n",
       "      <th>keyword_original_5</th>\n",
       "      <th>keyword_original_6</th>\n",
       "      <th>keyword_original_7</th>\n",
       "      <th>keyword_original_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just happened  terrible car crash</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>3</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is  forest fire at spot pond geese are f...</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>3</td>\n",
       "      <td>#spokane #wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_original keyword_original location_original  \\\n",
       "0            0              NaN               NaN   \n",
       "1            2              NaN               NaN   \n",
       "2            3              NaN               NaN   \n",
       "3            9              NaN               NaN   \n",
       "4           11              NaN               NaN   \n",
       "\n",
       "                                       text_original  special_chars_count  \\\n",
       "0                  just happened  terrible car crash                    0   \n",
       "1  heard about earthquake is different cities sta...                    3   \n",
       "2  there is  forest fire at spot pond geese are f...                    2   \n",
       "3              apocalypse lighting spokane wildfires                    3   \n",
       "4         typhoon soudelor kills in china and taiwan                    0   \n",
       "\n",
       "               hashtags labels  hashtags_count  labels_count  num_chars_count  \\\n",
       "0                   NaN    NaN               0             0                0   \n",
       "1          #earthquake     NaN               1             0                0   \n",
       "2                   NaN    NaN               0             0                0   \n",
       "3  #spokane #wildfires     NaN               2             0                0   \n",
       "4                   NaN    NaN               0             0                2   \n",
       "\n",
       "   ...  words_count keyword_original_0  keyword_original_1  \\\n",
       "0  ...            6                  0                   0   \n",
       "1  ...            9                  0                   0   \n",
       "2  ...           19                  0                   0   \n",
       "3  ...            4                  0                   0   \n",
       "4  ...            7                  0                   0   \n",
       "\n",
       "   keyword_original_2  keyword_original_3  keyword_original_4  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   keyword_original_5  keyword_original_6  keyword_original_7  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   keyword_original_8  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_original</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just happened  terrible car crash</td>\n",
       "      <td>happened terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heard about earthquake is different cities sta...</td>\n",
       "      <td>heard earthquake different cities stay safe ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is  forest fire at spot pond geese are f...</td>\n",
       "      <td>forest fire spot pond geese fleeing across str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "      <td>apocalypse lighting spokane wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>typhoon soudelor kills in china and taiwan</td>\n",
       "      <td>typhoon soudelor kills china taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>earthquake safety los angeles uo safety fasten...</td>\n",
       "      <td>earthquake safety los angeles uo safety fasten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>storm in ri worse than last hurricane my city ...</td>\n",
       "      <td>storm ri worse last hurricane city others hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>green line derailment in chicago</td>\n",
       "      <td>green line derailment chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>meg issues hazardous weather outlook hwo</td>\n",
       "      <td>meg issues hazardous weather outlook hwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>cityofcalgary has activated its municipal emer...</td>\n",
       "      <td>cityofcalgary activated municipal emergency pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_original  \\\n",
       "0                     just happened  terrible car crash   \n",
       "1     heard about earthquake is different cities sta...   \n",
       "2     there is  forest fire at spot pond geese are f...   \n",
       "3                 apocalypse lighting spokane wildfires   \n",
       "4            typhoon soudelor kills in china and taiwan   \n",
       "...                                                 ...   \n",
       "3258  earthquake safety los angeles uo safety fasten...   \n",
       "3259  storm in ri worse than last hurricane my city ...   \n",
       "3260                   green line derailment in chicago   \n",
       "3261           meg issues hazardous weather outlook hwo   \n",
       "3262  cityofcalgary has activated its municipal emer...   \n",
       "\n",
       "                                             clean_text  \n",
       "0                           happened terrible car crash  \n",
       "1     heard earthquake different cities stay safe ev...  \n",
       "2     forest fire spot pond geese fleeing across str...  \n",
       "3                 apocalypse lighting spokane wildfires  \n",
       "4                   typhoon soudelor kills china taiwan  \n",
       "...                                                 ...  \n",
       "3258  earthquake safety los angeles uo safety fasten...  \n",
       "3259  storm ri worse last hurricane city others hard...  \n",
       "3260                      green line derailment chicago  \n",
       "3261           meg issues hazardous weather outlook hwo  \n",
       "3262  cityofcalgary activated municipal emergency pl...  \n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[:,[\"text_original\",\"clean_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 27 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id_original          3263 non-null   int64  \n",
      " 1   keyword_original     3237 non-null   object \n",
      " 2   location_original    2158 non-null   object \n",
      " 3   text_original        3263 non-null   object \n",
      " 4   special_chars_count  3263 non-null   int64  \n",
      " 5   hashtags             773 non-null    object \n",
      " 6   labels               904 non-null    object \n",
      " 7   hashtags_count       3263 non-null   int64  \n",
      " 8   labels_count         3263 non-null   int64  \n",
      " 9   num_chars_count      3263 non-null   int64  \n",
      " 10  links_count          3263 non-null   int64  \n",
      " 11  clean_text           3262 non-null   object \n",
      " 12  text_length          3263 non-null   int64  \n",
      " 13  mean_word_length     3263 non-null   float64\n",
      " 14  vowels_count         3263 non-null   int64  \n",
      " 15  short_words_count    3263 non-null   int64  \n",
      " 16  stopwords_count      3263 non-null   int64  \n",
      " 17  words_count          3263 non-null   int64  \n",
      " 18  keyword_original_0   3263 non-null   int64  \n",
      " 19  keyword_original_1   3263 non-null   int64  \n",
      " 20  keyword_original_2   3263 non-null   int64  \n",
      " 21  keyword_original_3   3263 non-null   int64  \n",
      " 22  keyword_original_4   3263 non-null   int64  \n",
      " 23  keyword_original_5   3263 non-null   int64  \n",
      " 24  keyword_original_6   3263 non-null   int64  \n",
      " 25  keyword_original_7   3263 non-null   int64  \n",
      " 26  keyword_original_8   3263 non-null   int64  \n",
      "dtypes: float64(1), int64(20), object(6)\n",
      "memory usage: 688.4+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info() #quedo un nan en clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):        \n",
    "    clean_word = ''.join([char for char in word if char not in string.punctuation])\n",
    "    return clean_word\n",
    "\n",
    "def cleaning_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    text_tokenize = tokenizer.tokenize(text)\n",
    "    wordlist = []\n",
    "    for word in text_tokenize:\n",
    "        word = word.lower()\n",
    "        word = re.sub('(?P<url>https?://[^\\s]+)', ' ', word)\n",
    "        word = remove_punctuation(word)\n",
    "        word = re.sub(r'[^\\w]', ' ', word)\n",
    "        word = unidecode.unidecode(word)\n",
    "        word = re.sub(r'[0-9]','', word)\n",
    "        if((word != '')&(word != ' ')&(word not in stopwords)):\n",
    "            wordlist.append(word)\n",
    "    clean_text = ' '.join(wordlist)\n",
    "    return clean_text\n",
    "\n",
    "test[\"clean_text\"] = test[\"text_original\"].apply(lambda x: cleaning_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test, function, k):\n",
    "    fs = SelectKBest(score_func=function, k=k)\n",
    "    fs.fit(X_train, y_train)\n",
    "    X_train_fs = fs.transform(X_train)\n",
    "    X_test_fs = fs.transform(X_test)\n",
    "    return X_train_fs, X_test_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14190\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaalll</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aaemiddleaged</th>\n",
       "      <th>aal</th>\n",
       "      <th>aan</th>\n",
       "      <th>aannnd</th>\n",
       "      <th>aar</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zonewolf</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zotar</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaand  aaalll  aaarrrgghhh  aaemiddleaged  aal  aan  aannnd  aar  \\\n",
       "0   0    0       0       0            0              0    0    0       0    0   \n",
       "1   0    0       0       0            0              0    0    0       0    0   \n",
       "2   0    0       0       0            0              0    0    0       0    0   \n",
       "3   0    0       0       0            0              0    0    0       0    0   \n",
       "4   0    0       0       0            0              0    0    0       0    0   \n",
       "\n",
       "   ...  zones  zonewolf  zoom  zotar  zouma  zrnf  zss  zumiez  zurich  zzz  \n",
       "0  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "1  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "2  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "3  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "4  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "\n",
       "[5 rows x 14190 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english') #con binary=True me dió 0.726386\n",
    "vectorizer.fit(train[\"clean_text\"])\n",
    "\n",
    "vec_train = vectorizer.fit_transform(train[\"clean_text\"])\n",
    "feature_words = vectorizer.get_feature_names()\n",
    "print(len(feature_words))\n",
    "df_bow_train = pd.DataFrame(vec_train.toarray(), columns=feature_words)\n",
    "df_bow_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaalll</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aaemiddleaged</th>\n",
       "      <th>aal</th>\n",
       "      <th>aan</th>\n",
       "      <th>aannnd</th>\n",
       "      <th>aar</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zonewolf</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zotar</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 14190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaand  aaalll  aaarrrgghhh  aaemiddleaged  aal  aan  aannnd  aar  \\\n",
       "0   0    0       0       0            0              0    0    0       0    0   \n",
       "1   0    0       0       0            0              0    0    0       0    0   \n",
       "2   0    0       0       0            0              0    0    0       0    0   \n",
       "3   0    0       0       0            0              0    0    0       0    0   \n",
       "4   0    0       0       0            0              0    0    0       0    0   \n",
       "\n",
       "   ...  zones  zonewolf  zoom  zotar  zouma  zrnf  zss  zumiez  zurich  zzz  \n",
       "0  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "1  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "2  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "3  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "4  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "\n",
       "[5 rows x 14190 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_test = vectorizer.transform(test[\"clean_text\"])\n",
    "df_bow_test = pd.DataFrame(vec_test.toarray(), columns=feature_words)\n",
    "df_bow_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbswinston</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcnews</th>\n",
       "      <th>abe</th>\n",
       "      <th>abia</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zippednews</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aba  abandon  abandoned  abbott  abbswinston  abc  abcnews  abe  abia  \\\n",
       "0   0    0        0          0       0            0    0        0    0     0   \n",
       "1   0    0        0          0       0            0    0        0    0     0   \n",
       "2   0    0        0          0       0            0    0        0    0     0   \n",
       "3   0    0        0          0       0            0    0        0    0     0   \n",
       "4   0    0        0          0       0            0    0        0    0     0   \n",
       "\n",
       "   ...  zero  zimbabwe  zionism  zionist  zippednews  zombie  zone  zones  \\\n",
       "0  ...     0         0        0        0           0       0     0      0   \n",
       "1  ...     0         0        0        0           0       0     0      0   \n",
       "2  ...     0         0        0        0           0       0     0      0   \n",
       "3  ...     0         0        0        0           0       0     0      0   \n",
       "4  ...     0         0        0        0           0       0     0      0   \n",
       "\n",
       "   zouma  zss  \n",
       "0      0    0  \n",
       "1      0    0  \n",
       "2      0    0  \n",
       "3      0    0  \n",
       "4      0    0  \n",
       "\n",
       "[5 rows x 6049 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_bow_train = df_bow_train.loc[:,(df_bow_train.sum()>1)]\n",
    "filter_bow_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 6049)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_list = filter_bow_train.columns.tolist()\n",
    "filter_bow_test = df_bow_test.filter(items=filter_list)\n",
    "filter_bow_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 6077)\n",
      "(7613, 14218)\n",
      "(3263, 6076)\n",
      "(3263, 14217)\n"
     ]
    }
   ],
   "source": [
    "train_final_1 = pd.concat([train,filter_bow_train], axis=\"columns\")\n",
    "print(train_final_1.shape)\n",
    "train_final_2 = pd.concat([train,df_bow_train], axis=\"columns\")\n",
    "print(train_final_2.shape)\n",
    "test_final_1 = pd.concat([test,filter_bow_test], axis=\"columns\")\n",
    "print(test_final_1.shape)\n",
    "test_final_2 = pd.concat([test,df_bow_test], axis=\"columns\")\n",
    "print(test_final_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con las palabras con frecuencia mayor a 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 6069)\n",
      "(1904, 6069)\n"
     ]
    }
   ],
   "source": [
    "X = train_final_1.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"target_label\",\n",
    "                      \"clean_text\", \"hashtags\", \"labels\"], axis=1)\n",
    "y = train_final_1[\"target_label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=7,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=350, n_jobs=-1, num_leaves=14, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=350, num_leaves=14, max_depth=7, colsample_bytree=0.7, learning_rate=0.1, subsample=1, min_child_samples=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.807773\n"
     ]
    }
   ],
   "source": [
    "# con binary=true 0.802521\n",
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.782971\n"
     ]
    }
   ],
   "source": [
    "#b=true 0.780870\n",
    "kfold = KFold(n_splits=4)\n",
    "resultados = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784199\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=6)\n",
    "resultados = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_word_length</th>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_chars_count</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowels_count</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_chars_count</th>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importancia\n",
       "mean_word_length             269\n",
       "text_length                  202\n",
       "special_chars_count          168\n",
       "vowels_count                 137\n",
       "num_chars_count              135"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduciendo a 3000 features\n",
    "df_feat_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns, columns=[\"importancia\"]).\\\n",
    "        sort_values(by=\"importancia\",ascending=False)\n",
    "df_feat_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 3000)\n",
      "Index(['mean_word_length', 'text_length', 'special_chars_count',\n",
      "       'vowels_count', 'num_chars_count', 'words_count', 'stopwords_count',\n",
      "       'short_words_count', 'keyword_original_7', 'labels_count',\n",
      "       ...\n",
      "       'skinny', 'skin', 'skills', 'skill', 'skies', 'sketch', 'skanndtyagi',\n",
      "       'sj', 'size', 'skirt'],\n",
      "      dtype='object', length=3000)\n"
     ]
    }
   ],
   "source": [
    "list_fi = df_feat_importances.index[:3000].tolist()\n",
    "X_fi = X.filter(items=list_fi)\n",
    "print(X_fi.shape)\n",
    "print(X_fi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fi, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=500, num_leaves=31, max_depth=5, colsample_bytree=0.7, learning_rate=0.1, subsample=1, min_child_samples=10,\n",
    "                           min_child_weight=0.001)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.803571\n"
     ]
    }
   ],
   "source": [
    "# b=true 0.806197\n",
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.787351\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=4)\n",
    "resultados = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.788227\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=6)\n",
    "resultados = cross_val_score(model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_final_1.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"target_label\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "X_test = test_final_1.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "y_train = train_final_1[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fi = X_train.filter(items=list_fi)\n",
    "X_test_fi = X_test.filter(items=list_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 3000)\n",
      "(3263, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_fi.shape)\n",
    "print(X_test_fi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=500, num_leaves=31, max_depth=5, colsample_bytree=0.7, learning_rate=0.1, subsample=1, min_child_samples=10,\n",
    "                           min_child_weight=0.001)\n",
    "model.fit(X_train_fi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.722445\n"
     ]
    }
   ],
   "source": [
    "# con binary=true 0.726386\n",
    "kfold = KFold(n_splits=4)\n",
    "resultados = cross_val_score(model, X_train_fi, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_word_length</th>\n",
       "      <td>466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_chars_count</th>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_chars_count</th>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowels_count</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importancia\n",
       "mean_word_length             466\n",
       "text_length                  338\n",
       "special_chars_count          296\n",
       "num_chars_count              282\n",
       "vowels_count                 241"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduciendo aun mas las features\n",
    "df_feat_importances2 = pd.DataFrame(model.feature_importances_, index=X_train_fi.columns, columns=[\"importancia\"]).\\\n",
    "        sort_values(by=\"importancia\",ascending=False)\n",
    "df_feat_importances2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2545\n",
       "1        65\n",
       "3        58\n",
       "4        50\n",
       "2        48\n",
       "6        33\n",
       "7        29\n",
       "8        27\n",
       "5        22\n",
       "9        19\n",
       "10       15\n",
       "12       14\n",
       "11       13\n",
       "13        8\n",
       "14        6\n",
       "20        6\n",
       "17        4\n",
       "15        3\n",
       "19        3\n",
       "30        2\n",
       "27        2\n",
       "29        2\n",
       "49        2\n",
       "16        2\n",
       "18        1\n",
       "22        1\n",
       "24        1\n",
       "26        1\n",
       "28        1\n",
       "241       1\n",
       "32        1\n",
       "42        1\n",
       "46        1\n",
       "56        1\n",
       "192       1\n",
       "282       1\n",
       "223       1\n",
       "338       1\n",
       "466       1\n",
       "23        1\n",
       "25        1\n",
       "43        1\n",
       "57        1\n",
       "85        1\n",
       "155       1\n",
       "296       1\n",
       "Name: importancia, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances2[\"importancia\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 455)\n",
      "Index(['mean_word_length', 'text_length', 'special_chars_count',\n",
      "       'vowels_count', 'num_chars_count', 'words_count', 'stopwords_count',\n",
      "       'short_words_count', 'keyword_original_7', 'labels_count',\n",
      "       ...\n",
      "       'island', 'sick', 'signs', 'offensive', 'costlier', 'water', 'escape',\n",
      "       'looking', 'makes', 'version'],\n",
      "      dtype='object', length=455)\n"
     ]
    }
   ],
   "source": [
    "#nos quedamos con 455\n",
    "list_fi = df_feat_importances2.index[:455].tolist()\n",
    "X_fi = X.filter(items=list_fi)\n",
    "print(X_fi.shape)\n",
    "print(X_fi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fi, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=500, num_leaves=31, max_depth=5, colsample_bytree=0.7, learning_rate=0.1, \n",
    "                           subsample=1, min_child_samples=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.805672\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper_parametros = {\"n_estimators\":[200,300,500],\n",
    "                   \"max_depth\":[5,7,9,11],\n",
    "                   \"colsample_bytree\":[0.5,0.7],\n",
    "                   \"num_leaves\":[7,14,31],\n",
    "                   \"learning_rate\":[0.1],\n",
    "                   \"min_child_samples\":[10],\n",
    "                    \"n_jobs\": [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=0.7,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=5,\n",
       "                                      min_child_samples=10,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=500,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True, subsample=1,\n",
       "                                      subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7], 'learning_rate': [0.1],\n",
       "                         'max_depth': [5, 7, 9, 11], 'min_child_samples': [10],\n",
       "                         'n_estimators': [200, 300, 500], 'n_jobs': [1],\n",
       "                         'num_leaves': [7, 14, 31]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif = GridSearchCV(model, hiper_parametros, cv=4, scoring='accuracy')\n",
    "clasif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=11,\n",
      "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=500, n_jobs=1, num_leaves=14, objective=None,\n",
      "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "               subsample=1, subsample_for_bin=200000, subsample_freq=0)\n",
      "0.7899801301038986\n"
     ]
    }
   ],
   "source": [
    "print(clasif.best_estimator_)\n",
    "print(clasif.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6069, 1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5606\n",
       "1        75\n",
       "2        60\n",
       "5        51\n",
       "4        50\n",
       "3        47\n",
       "7        27\n",
       "6        25\n",
       "8        18\n",
       "10       17\n",
       "9        14\n",
       "11       14\n",
       "14        9\n",
       "12        8\n",
       "13        7\n",
       "17        4\n",
       "21        3\n",
       "25        3\n",
       "20        3\n",
       "19        3\n",
       "27        3\n",
       "24        2\n",
       "39        1\n",
       "43        1\n",
       "168       1\n",
       "124       1\n",
       "44        1\n",
       "28        1\n",
       "269       1\n",
       "97        1\n",
       "137       1\n",
       "35        1\n",
       "47        1\n",
       "18        1\n",
       "22        1\n",
       "30        1\n",
       "42        1\n",
       "118       1\n",
       "202       1\n",
       "15        1\n",
       "23        1\n",
       "135       1\n",
       "Name: importancia, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances[\"importancia\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 463)\n",
      "Index(['mean_word_length', 'text_length', 'special_chars_count',\n",
      "       'vowels_count', 'num_chars_count', 'words_count', 'stopwords_count',\n",
      "       'short_words_count', 'keyword_original_7', 'labels_count',\n",
      "       ...\n",
      "       'makes', 'version', 'likely', 'rescuers', 'emmerdale', 'engulfed',\n",
      "       'reuters', 'right', 'level', 'rly'],\n",
      "      dtype='object', length=463)\n"
     ]
    }
   ],
   "source": [
    "list_fi = df_feat_importances.index[:463].tolist()\n",
    "X_fi = X.filter(items=list_fi)\n",
    "print(X_fi.shape)\n",
    "print(X_fi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fi, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=500, num_leaves=31, max_depth=5, colsample_bytree=0.7, learning_rate=0.1, \n",
    "                           subsample=1, min_child_samples=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.803046\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper_parametros = {\"n_estimators\":[300,400,500],\n",
    "                   \"max_depth\":[5,7,9,11],\n",
    "                   \"colsample_bytree\":[0.5,0.7,0.8],\n",
    "                   \"num_leaves\":[7,14,31],\n",
    "                   \"learning_rate\":[0.1],\n",
    "                   \"min_child_samples\":[10],\n",
    "                    \"n_jobs\": [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score=nan,\n",
       "             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "                                      colsample_bytree=0.7,\n",
       "                                      importance_type='split',\n",
       "                                      learning_rate=0.1, max_depth=5,\n",
       "                                      min_child_samples=10,\n",
       "                                      min_child_weight=0.001,\n",
       "                                      min_split_gain=0.0, n_estimators=500,\n",
       "                                      n_jobs=-1, num_leaves=31, objective=None,\n",
       "                                      random_state=None, reg_alpha=0.0,\n",
       "                                      reg_lambda=0.0, silent=True...ample=1,\n",
       "                                      subsample_for_bin=200000,\n",
       "                                      subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7, 0.8],\n",
       "                         'learning_rate': [0.1], 'max_depth': [5, 7, 9, 11],\n",
       "                         'min_child_samples': [10],\n",
       "                         'n_estimators': [300, 400, 500], 'n_jobs': [1],\n",
       "                         'num_leaves': [7, 14, 31]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif = GridSearchCV(model, hiper_parametros, cv=4, scoring='accuracy')\n",
    "clasif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=11,\n",
      "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=400, n_jobs=1, num_leaves=14, objective=None,\n",
      "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "               subsample=1, subsample_for_bin=200000, subsample_freq=0)\n",
      "0.7926067939439265\n"
     ]
    }
   ],
   "source": [
    "print(clasif.best_estimator_)\n",
    "print(clasif.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_final_1.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"target_label\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "X_test = test_final_1.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "y_train = train_final_1[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fi = df_feat_importances.index[:463].tolist()\n",
    "X_train_fi = X_train.filter(items=list_fi)\n",
    "X_test_fi = X_test.filter(items=list_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 463)\n",
      "(3263, 463)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_fi.shape)\n",
    "print(X_test_fi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.5,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=11,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=400, n_jobs=-1, num_leaves=14, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=400, num_leaves=14, max_depth=11, colsample_bytree=0.5, learning_rate=0.1, \n",
    "                           subsample=1, min_child_samples=10)\n",
    "model.fit(X_train_fi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_fi)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_original  target\n",
       "0               0       0\n",
       "1               2       1\n",
       "2               3       1\n",
       "3               9       0\n",
       "4              11       1\n",
       "...           ...     ...\n",
       "3258        10861       1\n",
       "3259        10865       1\n",
       "3260        10868       1\n",
       "3261        10874       1\n",
       "3262        10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"target\"] = y_pred\n",
    "test[[\"id_original\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"id_original\",\"target\"]].rename(columns={\"id_original\":\"id\"}).to_csv(\"../data/pred14_LGBM_bowbin_fi\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Con todas las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 14209)\n",
      "(1904, 14209)\n"
     ]
    }
   ],
   "source": [
    "X = train_final_2.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"target_label\",\n",
    "                      \"clean_text\", \"hashtags\", \"labels\"], axis=1)\n",
    "y = train_final_2[\"target_label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=7,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=450, n_jobs=-1, num_leaves=14, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=450, num_leaves=14, max_depth=7, colsample_bytree=0.7, learning_rate=0.1, subsample=1, min_child_samples=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.808298\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_word_length</th>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special_chars_count</th>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_chars_count</th>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowels_count</th>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importancia\n",
       "mean_word_length             344\n",
       "text_length                  258\n",
       "special_chars_count          208\n",
       "num_chars_count              175\n",
       "vowels_count                 167"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances = pd.DataFrame(model.feature_importances_, index=X_train.columns, columns=[\"importancia\"]).\\\n",
    "        sort_values(by=\"importancia\",ascending=False)\n",
    "df_feat_importances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      13667\n",
       "1         95\n",
       "2         63\n",
       "6         48\n",
       "4         46\n",
       "3         44\n",
       "5         42\n",
       "7         36\n",
       "8         31\n",
       "9         18\n",
       "10        17\n",
       "13        13\n",
       "11        13\n",
       "14        11\n",
       "12        10\n",
       "16         7\n",
       "15         6\n",
       "30         3\n",
       "17         3\n",
       "20         3\n",
       "19         3\n",
       "22         3\n",
       "25         2\n",
       "49         2\n",
       "29         2\n",
       "21         2\n",
       "26         2\n",
       "36         2\n",
       "24         2\n",
       "56         1\n",
       "344        1\n",
       "144        1\n",
       "127        1\n",
       "208        1\n",
       "46         1\n",
       "54         1\n",
       "33         1\n",
       "154        1\n",
       "258        1\n",
       "167        1\n",
       "59         1\n",
       "175        1\n",
       "Name: importancia, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances[\"importancia\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 542)\n",
      "Index(['mean_word_length', 'text_length', 'special_chars_count',\n",
      "       'num_chars_count', 'vowels_count', 'stopwords_count', 'words_count',\n",
      "       'short_words_count', 'keyword_original_4', 'keyword_original_7',\n",
      "       ...\n",
      "       'help', 'terror', 'drowned', 'looks', 'words', 'episode', 'response',\n",
      "       'causing', 'emergency', 'takes'],\n",
      "      dtype='object', length=542)\n"
     ]
    }
   ],
   "source": [
    "# nos quedamos con las features con un valor de importancia mayor a 0\n",
    "list_fi = df_feat_importances.index[:542].tolist()\n",
    "X_fi = X.filter(items=list_fi)\n",
    "print(X_fi.shape)\n",
    "print(X_fi.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_fi, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=7, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=500, num_leaves=7, max_depth=5, colsample_bytree=0.7, learning_rate=0.1, \n",
    "                           subsample=1, min_child_samples=10)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.809874\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_final_2.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"target_label\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "X_test = test_final_2.drop([\"id_original\",\"keyword_original\",\"location_original\",\"text_original\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "y_train = train_final_2[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_fi = df_feat_importances.index[:542].tolist()\n",
    "X_train_fi = X_train.filter(items=list_fi)\n",
    "X_test_fi = X_test.filter(items=list_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=5,\n",
       "               min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=500, n_jobs=-1, num_leaves=7, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(n_estimators=500, num_leaves=7, max_depth=5, colsample_bytree=0.7, learning_rate=0.1, \n",
    "                           subsample=1, min_child_samples=10)\n",
    "model.fit(X_train_fi, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_fi)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_original  target\n",
       "0               0       0\n",
       "1               2       1\n",
       "2               3       1\n",
       "3               9       0\n",
       "4              11       1\n",
       "...           ...     ...\n",
       "3258        10861       1\n",
       "3259        10865       1\n",
       "3260        10868       1\n",
       "3261        10874       1\n",
       "3262        10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"target\"] = y_pred\n",
    "test[[\"id_original\",\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"id_original\",\"target\"]].rename(columns={\"id_original\":\"id\"}).to_csv(\"../data/pred15_LGBM_bowbin_fi\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
