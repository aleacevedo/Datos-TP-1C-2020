{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "import unidecode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(x,char):\n",
    "    words = \"\"\n",
    "    for word in x:\n",
    "        if word.startswith(char):\n",
    "            words = words + word + \" \"\n",
    "    return words\n",
    "\n",
    "def count_vowels(x):\n",
    "    return (x.count('a') + x.count('e') + x.count('i') + x.count('o') + x.count('u'))\n",
    "\n",
    "def count_short_words(x):\n",
    "    count = 0\n",
    "    words = x.split(' ')\n",
    "    for word in words:\n",
    "        if 1 <= len(word) <= 3:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def count_stopwords(x):\n",
    "    count = 0\n",
    "    words = x.split(' ')\n",
    "    for word in words:\n",
    "        if word in stopwords:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"special_chars_count\"] =  tweets[\"text\"]\n",
    "tweets[\"special_chars_count\"] =  tweets[\"special_chars_count\"].str.lower()\n",
    "tweets[\"special_chars_count\"] = tweets[\"special_chars_count\"].apply(lambda x: re.sub(r'[a-z]','',x))\n",
    "tweets[\"special_chars_count\"] = tweets[\"special_chars_count\"].str.strip()\n",
    "tweets[\"special_chars_count\"] = tweets[\"special_chars_count\"].apply(lambda x: re.sub(' +','', x))\n",
    "tweets[\"special_chars_count\"] = tweets[\"special_chars_count\"].apply(lambda x: re.sub(r'[0-9]','', x))\n",
    "tweets[\"special_chars_count\"] = tweets[\"special_chars_count\"].str.len()\n",
    "\n",
    "tweets[\"hashtags\"] = tweets[\"text\"].str.lower().str.split(' ').apply(lambda x: concatenate(x,'#'))\n",
    "tweets[\"labels\"] = tweets[\"text\"].str.lower().str.split(' ').apply(lambda x: concatenate(x,'@'))\n",
    "tweets[\"hashtags_count\"] = tweets[\"hashtags\"].str.split(' ').apply(lambda x: len(x))-1\n",
    "tweets[\"labels_count\"] = tweets[\"labels\"].str.split(' ').apply(lambda x: len(x))-1\n",
    "\n",
    "tweets[\"num_chars_count\"] = tweets[\"text\"]\n",
    "tweets[\"num_chars_count\"] =  tweets[\"num_chars_count\"].str.lower()\n",
    "tweets[\"num_chars_count\"] = tweets[\"num_chars_count\"].apply(lambda x: re.sub(r'[a-z]','',x))\n",
    "tweets[\"num_chars_count\"] = tweets[\"num_chars_count\"].apply(lambda x: re.sub(r'[^\\w]','',x))\n",
    "tweets[\"num_chars_count\"] = tweets[\"num_chars_count\"].str.strip()\n",
    "tweets[\"num_chars_count\"] = tweets[\"num_chars_count\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(word):        \n",
    "    clean_word = ''.join([char for char in word if char not in string.punctuation])\n",
    "    return clean_word\n",
    "\n",
    "def cleaning_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    text_tokenize = tokenizer.tokenize(text)\n",
    "    wordlist = []\n",
    "    for word in text_tokenize:\n",
    "        word = word.lower()\n",
    "        word = re.sub('(?P<url>https?://[^\\s]+)', ' ', word)\n",
    "        word = remove_punctuation(word)\n",
    "        word = re.sub(r'[^\\w]', ' ', word)\n",
    "        word = unidecode.unidecode(word)\n",
    "        word = re.sub(r'[0-9]','', word)\n",
    "        if((word != '')&(word != ' ')&(word not in stopwords)):\n",
    "            wordlist.append(word)\n",
    "    clean_text = ' '.join(wordlist)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0       1                    1         #earthquake                       1   \n",
       "1       1                    1                                           0   \n",
       "2       1                    3                                           0   \n",
       "3       1                    2          #wildfires                       1   \n",
       "4       1                    2  #alaska #wildfires                       2   \n",
       "\n",
       "   labels_count  num_chars_count  \\\n",
       "0             0                0   \n",
       "1             0                0   \n",
       "2             0                0   \n",
       "3             0                5   \n",
       "4             0                0   \n",
       "\n",
       "                                          clean_text  \n",
       "0       deeds reason earthquake may allah forgive us  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  residents asked shelter place notified officer...  \n",
       "3  people receive wildfires evacuation orders cal...  \n",
       "4  got sent photo ruby alaska smoke wildfires pou...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"clean_text\"] = tweets[\"text\"].apply(lambda x: cleaning_text(x))\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].str.lower()\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub('(?P<url>https?://[^\\s]+)', ' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'[^\\w]', ' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'_', ' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'[0-9]',' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(' +',' ', x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: unidecode.unidecode(x))\n",
    "tweets[\"text\"] = tweets[\"text\"].str.strip()\n",
    "tweets[\"text_length\"] = tweets[\"text\"].str.len()\n",
    "\n",
    "tweets[\"vowels_count\"] = tweets[\"text\"].apply(lambda x: count_vowels(x))\n",
    "tweets[\"short_words_count\"] = tweets[\"text\"].apply(lambda x: count_short_words(x))\n",
    "tweets[\"stopwords_count\"] = tweets[\"text\"].apply(lambda x: count_stopwords(x))\n",
    "tweets[\"text\"] = tweets[\"text\"].apply(lambda x: re.sub(r'\\b\\w{1}\\b', '', x))\n",
    "tweets[\"words_count\"] = tweets[\"text\"].str.split(' ').apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target_label</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>vowels_count</th>\n",
       "      <th>short_words_count</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>68</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>130</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>56</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  people receive wildfires evacuation orders in ...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target_label  special_chars_count             hashtags labels  \\\n",
       "0             1                    1         #earthquake           \n",
       "1             1                    1                               \n",
       "2             1                    3                               \n",
       "3             1                    2          #wildfires           \n",
       "4             1                    2  #alaska #wildfires           \n",
       "\n",
       "   hashtags_count  labels_count  num_chars_count  \\\n",
       "0               1             0                0   \n",
       "1               0             0                0   \n",
       "2               0             0                0   \n",
       "3               1             0                5   \n",
       "4               2             0                0   \n",
       "\n",
       "                                          clean_text  text_length  \\\n",
       "0       deeds reason earthquake may allah forgive us           68   \n",
       "1              forest fire near la ronge sask canada           37   \n",
       "2  residents asked shelter place notified officer...          130   \n",
       "3  people receive wildfires evacuation orders cal...           56   \n",
       "4  got sent photo ruby alaska smoke wildfires pou...           85   \n",
       "\n",
       "   vowels_count  short_words_count  stopwords_count  words_count  \n",
       "0            25                  7                6           13  \n",
       "1            13                  1                0            7  \n",
       "2            45                  9               11           22  \n",
       "3            24                  1                1            7  \n",
       "4            25                  3                7           16  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.rename(columns={\"target\":\"target_label\"}, inplace=True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BOW\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "df_text = tweets[\"clean_text\"]\n",
    "X = vectorizer.fit_transform(df_text)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_words = vectorizer.get_feature_names()\n",
    "len(feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaand</th>\n",
       "      <th>aaalll</th>\n",
       "      <th>aaarrrgghhh</th>\n",
       "      <th>aaemiddleaged</th>\n",
       "      <th>aal</th>\n",
       "      <th>aan</th>\n",
       "      <th>aannnd</th>\n",
       "      <th>aar</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zonewolf</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zotar</th>\n",
       "      <th>zouma</th>\n",
       "      <th>zrnf</th>\n",
       "      <th>zss</th>\n",
       "      <th>zumiez</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 14190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaa  aaaand  aaalll  aaarrrgghhh  aaemiddleaged  aal  aan  aannnd  aar  \\\n",
       "0   0    0       0       0            0              0    0    0       0    0   \n",
       "1   0    0       0       0            0              0    0    0       0    0   \n",
       "2   0    0       0       0            0              0    0    0       0    0   \n",
       "3   0    0       0       0            0              0    0    0       0    0   \n",
       "4   0    0       0       0            0              0    0    0       0    0   \n",
       "\n",
       "   ...  zones  zonewolf  zoom  zotar  zouma  zrnf  zss  zumiez  zurich  zzz  \n",
       "0  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "1  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "2  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "3  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "4  ...      0         0     0      0      0     0    0       0       0    0  \n",
       "\n",
       "[5 rows x 14190 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame(X.toarray(), columns=feature_words)\n",
    "df_words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 2080)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter = df_words.loc[:,(df_words.sum()>5)]\n",
    "df_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 2097)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_final = pd.concat([tweets,df_filter], axis=\"columns\")\n",
    "tweets_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_final.drop([\"id\",\"keyword\",\"location\",\"text\",\"target_label\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "y = tweets_final[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5709, 2087)\n",
      "(1904, 2087)\n",
      "(5709,)\n",
      "(1904,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usando las 2087 features\n",
    "model_lgb = lgb.LGBMClassifier()\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.779937\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([98, 12, 35, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vamos a reducir las 2087 features a las 600 mas importantes\n",
    "model_lgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_importances = pd.DataFrame(model_lgb.feature_importances_, index=X_train.columns, columns=[\"importancia\"]).\\\n",
    "        sort_values(by=\"importancia\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>special_chars_count</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowels_count</th>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_words_count</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_count</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_chars_count</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words_count</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels_count</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiroshima</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spill</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fires</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derailment</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disaster</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>israeli</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killed</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>near</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importancia\n",
       "special_chars_count           98\n",
       "text_length                   97\n",
       "vowels_count                  81\n",
       "short_words_count             62\n",
       "stopwords_count               60\n",
       "num_chars_count               52\n",
       "words_count                   45\n",
       "labels_count                  35\n",
       "hiroshima                     33\n",
       "spill                         29\n",
       "buildings                     29\n",
       "fires                         28\n",
       "earthquake                    28\n",
       "derailment                    27\n",
       "disaster                      25\n",
       "storm                         24\n",
       "suicide                       24\n",
       "israeli                       21\n",
       "killed                        21\n",
       "near                          21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 600)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fi = df_feat_importances.index[:600].tolist()\n",
    "X = X.filter(items=list_fi)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usando las 600 features\n",
    "model_lgb = lgb.LGBMClassifier()\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.779937\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustando hiper-parametros:\n",
    "    - n_estimators=100, num_leaves=7, colsample_bytree=0.3, subsample=1, max_depth=4, learning_rate=0.1\n",
    "    SCORE: 0.758929\n",
    "    - n_estimators=150, num_leaves=7, colsample_bytree=0.3, subsample=1, max_depth=4, learning_rate=0.1\n",
    "    SCORE: 0.769958\n",
    "    - n_estimators=200, num_leaves=7, colsample_bytree=0.3, subsample=1, max_depth=4, learning_rate=0.1\n",
    "    SCORE: 0.777836\n",
    "    - n_estimators=250, num_leaves=7, colsample_bytree=0.3, subsample=1, max_depth=4, learning_rate=0.1\n",
    "    SCORE: 0.780462\n",
    "    - n_estimators=300, num_leaves=7, colsample_bytree=0.3, subsample=1, max_depth=4, learning_rate=0.1\n",
    "    SCORE: 0.778887\n",
    "    - n_estimators=260, num_leaves=7, colsample_bytree=0.3, subsample=1, max_depth=4, learning_rate=0.1\n",
    "    SCORE: 0.780987\n",
    "#### Con Grid-Search 4-fold:\n",
    "    - n_estimators=260, max_depth=7, colsample_bytree=0.3, learning_rate=0.1\n",
    "    SCORE: 0.760899\n",
    "    - n_estimators=260, max_depth=7, colsample_bytree=0.5, learning_rate=0.1\n",
    "    SCORE: 0.763527\n",
    "    - n_estimators=260, max_depth=7, colsample_bytree=0.7, learning_rate=0.1\n",
    "    SCORE: 0.764403"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.3, max_depth=4, n_estimators=255, n_jobs=1,\n",
       "               num_leaves=7, objective='binary', subsample=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMClassifier(num_leaves=7, objective=\"binary\", colsample_bytree=0.3, subsample=1, max_depth=4, n_jobs=1,\n",
    "                              n_estimators=260, min_child_samples=20, learning_rate=0.1)\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.780462\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper_parametros = {\"num_leaves\":[7],\n",
    "                   \"max_depth\":[7],\n",
    "                    \"n_estimators\":[200],\n",
    "                   \"colsample_bytree\":[0.3,0.5,0.7],\n",
    "                   \"learning_rate\":[0.1,0.05,0.2],\n",
    "                    \"n_jobs\": [1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, estimator=LGBMClassifier(),\n",
       "             param_grid={'colsample_bytree': [0.3, 0.5, 0.7],\n",
       "                         'learning_rate': [0.1, 0.05, 0.2], 'max_depth': [7],\n",
       "                         'n_estimators': [200], 'n_jobs': [1],\n",
       "                         'num_leaves': [7]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasif = GridSearchCV(model_lgb, hiper_parametros, cv=4, scoring='accuracy')\n",
    "clasif.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(colsample_bytree=0.7, learning_rate=0.2, max_depth=7,\n",
      "               n_estimators=200, n_jobs=1, num_leaves=7)\n",
      "0.7614258036781637\n"
     ]
    }
   ],
   "source": [
    "print(clasif.best_estimator_)\n",
    "print(clasif.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ahora con tf-idf\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(tweets[\"clean_text\"])\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 2072)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.DataFrame(X.toarray(), columns=feature_words)\n",
    "df_filter = df_words.loc[:,(df_words.sum()>2)]\n",
    "df_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 2089)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_final = pd.concat([tweets,df_filter], axis=\"columns\")\n",
    "tweets_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_final.drop([\"id\",\"keyword\",\"location\",\"text\",\"target_label\",\"hashtags\",\"labels\",\"clean_text\"], axis=1)\n",
    "y = tweets_final[\"target_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usando las 2089 features\n",
    "model_lgb = lgb.LGBMClassifier()\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.792542\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_importances = pd.DataFrame(model_lgb.feature_importances_, index=X_train.columns, columns=[\"importancia\"]).\\\n",
    "        sort_values(by=\"importancia\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 700)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fi = df_feat_importances.index[:700].tolist()\n",
    "X = X.filter(items=list_fi)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usando 700 features\n",
    "model_lgb = lgb.LGBMClassifier()\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.792542\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.7, learning_rate=0.15, max_depth=7,\n",
       "               min_child_samples=10, n_estimators=250, n_jobs=1, num_leaves=14,\n",
       "               objective='binary', subsample=1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMClassifier(num_leaves=14, objective=\"binary\", colsample_bytree=0.7, subsample=1, max_depth=7, n_jobs=1,\n",
    "                              n_estimators=250, min_child_samples=10, learning_rate=0.15)\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.786239\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([168, 158, 161, 141, 125, 110,  35,  29,  18,  16,  23,  22, 103,\n",
       "        36,  12,  16,  15,  18,  17,  19,  12,  14,  18,  17,  17,  14,\n",
       "        12,  10,  15,  13,  18,  11,  13,  14,  12,  11,  13,  12,  11,\n",
       "        11,  11,  11,   9,  13,  12,  10,   8,  11,  10,  15,  12,  14,\n",
       "        12,  11,  11,   9,  10,   9,  10,   9,  11,   7,   6,  12,  12,\n",
       "        11,   9,  10,   8,  12,   9,   9,   8,   9,  10,   9,   7,   6,\n",
       "         6,   5,   7,  14,  12,   8,   6,   2,  11,   7,   4,   8,   4,\n",
       "         6,   8,   5,   7,   8,   8,   3,   9,   5,   9,   4,   6,   5,\n",
       "         7,   7,  10,   7,   5,   4,   5,   5,   6,  22,  11,   9,   9,\n",
       "         7,   9,   6,   7,   5,   8,   8,   6,   4,   5,   6,  10,   8,\n",
       "         8,   7,   7,   5,  11,   9,   9,   5,   9,   6,   4,   5,   5,\n",
       "         7,   6,   4,   5,   4,   5,  10,   8,   5,   6,   8,   4,   7,\n",
       "         5,   5,   6,   9,   2,   5,   2,   4,   7,   9,   6,   4,   3,\n",
       "         7,   4,   4,   3,   3,   5,   5,   4,   5,   4,   5,   3,   4,\n",
       "         3,   4,   4,   4,   7,   3,   5,   0,   4,  11,   3,   3,   5,\n",
       "         4,   3,   5,   5,   3,   0,   3,   3,   3,   1,   4,   4,   3,\n",
       "         3,   5,   2,   3,   3,   2,   3,   3,   2,   3,   7,   2,   3,\n",
       "         2,   3,   2,   1,   3,   7,   2,   0,   3,   1,   6,   1,   1,\n",
       "         4,   2,   2,   3,   1,   3,   3,   5,   3,   2,   0,   1,   0,\n",
       "         3,   0,   5,   3,   2,   2,   1,   2,   7,   2,   0,   9,   2,\n",
       "         0,   3,   4,   1,   1,   5,   1,   0,   0,   2,   0,   1,   5,\n",
       "         0,   1,   2,   0,   0,   0,   1,   1,   1,   1,   2,   7,   2,\n",
       "         4,   1,   0,   1,   1,   0,   1,   0,   1,   7,   0,   1,   5,\n",
       "         0,   4,   1,   0,   0,   0,   0,   3,   0,   1,   1,   0,   1,\n",
       "         0,   1,   2,   0,   0,   0,   0,   3,   0,   4,   0,   1,   2,\n",
       "         0,   1,   0,   2,   0,   1,   0,   0,   1,   0,   3,   3,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "         0,   0,   5,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   2,   0,   3,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "         0,   0,   0,   0,   0,   0,   6,   0,   0,   0,   0,   3,   0,\n",
       "         1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   5,   0,\n",
       "         0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   1,   0,   2,   0,   3,   0,   0,   2,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   7,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   1,   0,\n",
       "         6,   0,   0,   1,   4,   0,   5,   0,   0,   0,   0,   0,   2,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   8,   0,   0,   0,   2,\n",
       "         2,   0,   0,   0,   5,   0,   0,   0,   0,   0,   0,   4,   0,\n",
       "         3,   0,   0,   1,   0,   3,   0,   0,   0,   0,   0,   1,   0,\n",
       "         3,   0,   0,   0,   0,   0,   0,   3,   0,   0,   0,   4,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   3,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         2,   0,  10,   0,   0,   2,   0,   2,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   1,   0,   0,   0,   0,   7,   5,   5,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   6,   0,   0,   0,   0,\n",
       "         1,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   1,   0,   0,   2,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   1])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat_importances = pd.DataFrame(model_lgb.feature_importances_, index=X_train.columns, columns=[\"importancia\"]).\\\n",
    "        sort_values(by=\"importancia\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importancia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>special_chars_count</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vowels_count</th>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_length</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stopwords_count</th>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_words_count</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_chars_count</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words_count</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels_count</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiroshima</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fires</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hashtags_count</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>california</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wildfire</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>casualties</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mass</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spill</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disaster</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derailment</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mh</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>migrants</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>killed</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     importancia\n",
       "special_chars_count          168\n",
       "vowels_count                 161\n",
       "text_length                  158\n",
       "stopwords_count              141\n",
       "short_words_count            125\n",
       "num_chars_count              110\n",
       "words_count                  103\n",
       "labels_count                  36\n",
       "hiroshima                     35\n",
       "fires                         29\n",
       "earthquake                    23\n",
       "storm                         22\n",
       "hashtags_count                22\n",
       "suicide                       19\n",
       "buildings                     18\n",
       "california                    18\n",
       "wildfire                      18\n",
       "casualties                    18\n",
       "mass                          17\n",
       "floods                        17\n",
       "train                         17\n",
       "spill                         16\n",
       "disaster                      16\n",
       "derailment                    15\n",
       "new                           15\n",
       "mh                            15\n",
       "migrants                      14\n",
       "killed                        14\n",
       "car                           14\n",
       "body                          14"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      348\n",
       "1       44\n",
       "3       44\n",
       "2       42\n",
       "5       39\n",
       "4       31\n",
       "7       24\n",
       "6       20\n",
       "9       20\n",
       "8       15\n",
       "11      15\n",
       "12      12\n",
       "10      11\n",
       "14       5\n",
       "18       4\n",
       "13       4\n",
       "15       3\n",
       "17       3\n",
       "16       2\n",
       "22       2\n",
       "161      1\n",
       "19       1\n",
       "23       1\n",
       "29       1\n",
       "35       1\n",
       "36       1\n",
       "103      1\n",
       "110      1\n",
       "125      1\n",
       "141      1\n",
       "158      1\n",
       "168      1\n",
       "Name: importancia, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat_importances[\"importancia\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 352)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_fi = df_feat_importances.index[:352].tolist()\n",
    "X = X.filter(items=list_fi)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.6, learning_rate=0.2, max_depth=7,\n",
       "               min_child_samples=10, n_estimators=300, n_jobs=1, num_leaves=14,\n",
       "               objective='binary', reg_lambda=1, subsample=1)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#usando 352 features\n",
    "model_lgb = lgb.LGBMClassifier(num_leaves=14, objective=\"binary\", colsample_bytree=0.6, subsample=1, max_depth=7, n_jobs=1,\n",
    "                              n_estimators=300, min_child_samples=10, reg_lambda=1, learning_rate=0.2)\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.797269\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = model_lgb.predict(X_test)\n",
    "print(\"Accuracy score: %f\" % (accuracy_score(y_test, y_test_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMClassifier(num_leaves=14, objective=\"binary\", colsample_bytree=0.6, subsample=1, max_depth=7, n_jobs=1,\n",
    "                              n_estimators=300, min_child_samples=10, reg_lambda=1, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.191889\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=6, random_state=100)\n",
    "resultados = cross_val_score(model_lgb, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.016911\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=6, random_state=100)\n",
    "resultados = cross_val_score(model_lgb, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %f\" % (resultados.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
