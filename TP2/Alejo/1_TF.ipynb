{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-446d4d38541b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:20,.2f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;31m# suprimimos la notacion cientifica en los outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# importacion general de librerias y de visualizacion (matplotlib y seaborn)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "pd.options.display.float_format = '{:20,.2f}'.format # suprimimos la notacion cientifica en los outputs\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_original</th>\n",
       "      <th>keyword_original</th>\n",
       "      <th>location_original</th>\n",
       "      <th>text_original</th>\n",
       "      <th>target_label</th>\n",
       "      <th>special_chars_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>labels</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>labels_count</th>\n",
       "      <th>num_chars_count</th>\n",
       "      <th>links_count</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_length</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>vowels_count</th>\n",
       "      <th>short_words_count</th>\n",
       "      <th>stopwords_count</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deeds reason earthquake may allah forgive us</td>\n",
       "      <td>68</td>\n",
       "      <td>4.31</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>37</td>\n",
       "      <td>4.43</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>130</td>\n",
       "      <td>4.95</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>56</td>\n",
       "      <td>7.14</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>#alaska #wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>85</td>\n",
       "      <td>4.38</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_original keyword_original location_original  \\\n",
       "0            1              NaN               NaN   \n",
       "1            4              NaN               NaN   \n",
       "2            5              NaN               NaN   \n",
       "3            6              NaN               NaN   \n",
       "4            7              NaN               NaN   \n",
       "\n",
       "                                       text_original  target_label  \\\n",
       "0  our deeds are the reason of this earthquake ma...             1   \n",
       "1              forest fire near la ronge sask canada             1   \n",
       "2  all residents asked to shelter in place are be...             1   \n",
       "3  people receive wildfires evacuation orders in ...             1   \n",
       "4  just got sent this photo from ruby alaska as s...             1   \n",
       "\n",
       "   special_chars_count             hashtags labels  hashtags_count  \\\n",
       "0                    1         #earthquake     NaN               1   \n",
       "1                    1                  NaN    NaN               0   \n",
       "2                    3                  NaN    NaN               0   \n",
       "3                    2          #wildfires     NaN               1   \n",
       "4                    2  #alaska #wildfires     NaN               2   \n",
       "\n",
       "   labels_count  num_chars_count  links_count  \\\n",
       "0             0                0            0   \n",
       "1             0                0            0   \n",
       "2             0                0            0   \n",
       "3             0                5            0   \n",
       "4             0                0            0   \n",
       "\n",
       "                                          clean_text  text_length  \\\n",
       "0       deeds reason earthquake may allah forgive us           68   \n",
       "1              forest fire near la ronge sask canada           37   \n",
       "2  residents asked shelter place notified officer...          130   \n",
       "3  people receive wildfires evacuation orders cal...           56   \n",
       "4  got sent photo ruby alaska smoke wildfires pou...           85   \n",
       "\n",
       "      mean_word_length  vowels_count  short_words_count  stopwords_count  \\\n",
       "0                 4.31            25                  7                6   \n",
       "1                 4.43            13                  1                0   \n",
       "2                 4.95            45                  9               11   \n",
       "3                 7.14            24                  1                1   \n",
       "4                 4.38            25                  3                7   \n",
       "\n",
       "   words_count  \n",
       "0           13  \n",
       "1            7  \n",
       "2           22  \n",
       "3            7  \n",
       "4           16  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('~/Documents/Datos/DataSets/TP2/train_featured.csv')\n",
    "test_data = pd.read_csv('~/Documents/Datos/DataSets/TP2/test_featured.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Dropout, Concatenate\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data['target_label'].values.tolist()\n",
    "data = train_data['clean_text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = \\\n",
    "    train_test_split(data,target, test_size=0.2)  # random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x14d392438>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()             #Tokenizer(num_words=5000) => 5000 words of the highest frequency\n",
    "tokenizer.fit_on_texts(data)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tokenizer) : 14368\n"
     ]
    }
   ],
   "source": [
    "print(\"len(tokenizer) :\",len(list(tokenizer.word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97425456456062"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_tokens : [549, 677, 244, 1, 63, 1904, 1311, 1437, 160, 549, 677, 244, 1, 63, 1904]\n",
      "x_train_pad : [   0  549  677  244    1   63 1904 1311 1437  160  549  677  244    1\n",
      "   63 1904]\n"
     ]
    }
   ],
   "source": [
    "#Zero is added before the values given in the padding operation.\n",
    "\n",
    "print(\"x_train_tokens :\",x_train_tokens[0])\n",
    "print(\"x_train_pad :\",x_train_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_pad.shape : (6090, 16)\n",
      "x_train_pad.shape : (1523, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train_pad.shape :\",x_train_pad.shape)\n",
    "print(\"x_train_pad.shape :\",x_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token!=0]\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experts france begin examining airplane debris found reunion island french air accident experts wedn'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[800]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[805, 895, 1141, 1334, 353, 156, 141, 402, 284, 1335, 224, 55, 805, 4263]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens[800])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experts france begin examining airplane debris found reunion island french air accident experts wedn'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[800])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_stopwords = []\n",
    "filtered_stopwords_list = []\n",
    "\n",
    "for i in data:\n",
    "    filtered_sentence = [w for w in i]\n",
    "    filtered_stopwords_list.append(filtered_sentence)                         #return list value\n",
    "    filtered_stopwords.append(\" \".join(filtered_sentence))                    #return string value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-06 18:40:41,615 : INFO : collecting all words and their counts\n",
      "2020-08-06 18:40:41,616 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-06 18:40:41,669 : INFO : collected 28 word types from a corpus of 456453 raw words and 7613 sentences\n",
      "2020-08-06 18:40:41,670 : INFO : Loading a fresh vocabulary\n",
      "2020-08-06 18:40:41,670 : INFO : effective_min_count=5 retains 28 unique words (100% of original 28, drops 0)\n",
      "2020-08-06 18:40:41,671 : INFO : effective_min_count=5 leaves 456453 word corpus (100% of original 456453, drops 0)\n",
      "2020-08-06 18:40:41,672 : INFO : deleting the raw counts dictionary of 28 items\n",
      "2020-08-06 18:40:41,672 : INFO : sample=0.001 downsamples 23 most-common words\n",
      "2020-08-06 18:40:41,673 : INFO : downsampling leaves estimated 79036 word corpus (17.3% of prior 456453)\n",
      "2020-08-06 18:40:41,674 : INFO : estimated required memory for 28 words and 1000 dimensions: 238000 bytes\n",
      "2020-08-06 18:40:41,674 : INFO : resetting layer weights\n",
      "2020-08-06 18:40:41,691 : INFO : training model with 3 workers on 28 vocabulary and 1000 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-08-06 18:40:41,843 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-06 18:40:41,845 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-06 18:40:41,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-06 18:40:41,846 : INFO : EPOCH - 1 : training on 456453 raw words (78876 effective words) took 0.2s, 524825 effective words/s\n",
      "2020-08-06 18:40:41,992 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-06 18:40:41,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-06 18:40:41,996 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-06 18:40:41,997 : INFO : EPOCH - 2 : training on 456453 raw words (78894 effective words) took 0.1s, 539634 effective words/s\n",
      "2020-08-06 18:40:42,143 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-06 18:40:42,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-06 18:40:42,147 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-06 18:40:42,148 : INFO : EPOCH - 3 : training on 456453 raw words (79160 effective words) took 0.1s, 538249 effective words/s\n",
      "2020-08-06 18:40:42,293 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-06 18:40:42,298 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-06 18:40:42,299 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-06 18:40:42,299 : INFO : EPOCH - 4 : training on 456453 raw words (79214 effective words) took 0.1s, 540333 effective words/s\n",
      "2020-08-06 18:40:42,444 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-06 18:40:42,449 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-06 18:40:42,450 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-06 18:40:42,450 : INFO : EPOCH - 5 : training on 456453 raw words (78843 effective words) took 0.1s, 540257 effective words/s\n",
      "2020-08-06 18:40:42,451 : INFO : training on a 2282265 raw words (394987 effective words) took 0.8s, 520637 effective words/s\n",
      "2020-08-06 18:40:42,451 : INFO : storing 28x1000 projection weights into 3000tweets_notbinary\n"
     ]
    }
   ],
   "source": [
    "#Save word2vec format (not binary)\n",
    "\n",
    "model = Word2Vec(filtered_stopwords_list, size=1000)\n",
    "model_save_location = \"3000tweets_notbinary\"\n",
    "model.wv.save_word2vec_format(model_save_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Word2vec load(2.option) example\n",
    "\n",
    "word2vec = {}\n",
    "with open('3000tweets_notbinary', encoding='UTF-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test[0] : alex making watch facts minions want fall cliff help\n",
      "x_test_pad[0] : [   0    0    0    0    0    0    0  685 2312   25   89  709 1060 4480\n",
      "  671 4481]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"x_test[0] :\",x_test[40])\n",
    "print(\"x_test_pad[0] :\",x_test_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(list(tokenizer.word_index)) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.uniform(-1, 1, (num_words, embedding_size))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < num_words:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14369, 1000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.93409523e-01,  3.84118369e-01,  6.95945573e-01,  7.29381563e-01,\n",
       "        5.53385736e-01,  2.24626343e-01, -3.05124016e-01, -5.91050699e-01,\n",
       "       -2.11955462e-01, -8.88838877e-01, -8.16972188e-01, -4.87341610e-01,\n",
       "        9.66319900e-01,  3.15930875e-01,  4.70544899e-01,  2.76626520e-01,\n",
       "       -6.28581320e-01,  1.58175821e-01,  2.34742139e-01, -2.26463842e-01,\n",
       "       -6.74042861e-02,  4.95473198e-01,  7.35480654e-01, -1.53020114e-01,\n",
       "       -6.27996585e-01,  8.34729513e-01,  1.61373133e-01, -9.38528590e-01,\n",
       "        6.07812038e-01, -9.21655357e-01, -7.81224773e-01,  9.75251348e-02,\n",
       "       -3.78557272e-01,  1.21502409e-01, -9.08726531e-01,  8.65587050e-01,\n",
       "       -7.06353924e-01, -6.51708505e-01, -2.14730170e-01,  4.53398779e-02,\n",
       "       -7.27353696e-01, -2.44400020e-01,  6.69351384e-01,  5.73899714e-01,\n",
       "        2.19046228e-01, -6.85704461e-01,  7.06881574e-01,  1.95838391e-01,\n",
       "       -9.37791741e-02, -4.87151030e-01,  4.57760351e-01,  3.65106162e-01,\n",
       "        2.76482071e-01,  4.90392820e-01,  5.68173782e-01, -3.83398788e-01,\n",
       "        9.76567629e-01,  4.11677424e-01, -5.02635377e-01,  2.59945067e-01,\n",
       "        8.83669835e-01,  3.06406390e-01, -8.15129545e-01, -2.13416203e-01,\n",
       "       -5.87468546e-01,  2.30244899e-01,  7.90511983e-01,  7.09009116e-01,\n",
       "       -7.82788057e-01, -9.30000871e-01, -6.62013978e-01,  3.78271863e-01,\n",
       "        9.21427769e-01,  5.00431583e-01,  2.95767930e-01,  1.45128414e-02,\n",
       "       -4.34246369e-01,  3.21880013e-01,  2.20600912e-01, -4.14395281e-01,\n",
       "        6.24755233e-01, -9.32915969e-02, -5.71999604e-01, -2.05155486e-03,\n",
       "        6.46661126e-01,  3.53113016e-03,  4.18698548e-01, -1.36969173e-01,\n",
       "       -7.81151089e-01,  4.15468116e-01,  7.58003511e-01, -1.45125028e-02,\n",
       "       -5.61157212e-01, -1.51784354e-01,  9.26856890e-01,  9.76648995e-01,\n",
       "        1.66876956e-01, -1.39640600e-01,  4.02123179e-01, -3.02205137e-01,\n",
       "        9.61354848e-01,  3.23816764e-01,  9.33767579e-01,  2.38247567e-01,\n",
       "       -6.80690363e-01, -6.39289051e-01, -5.87301580e-01, -5.69984449e-01,\n",
       "        2.66765756e-02, -3.67560907e-01,  3.32091609e-01, -3.23995283e-01,\n",
       "        3.15407095e-01, -2.07356171e-01, -6.14233789e-02,  5.55173358e-01,\n",
       "        3.01414495e-01, -7.12244517e-01,  3.28998325e-01,  4.26551430e-01,\n",
       "        3.57704792e-01, -1.37196593e-01, -6.54220776e-01, -3.94630868e-01,\n",
       "       -8.41383932e-01, -1.23874639e-01, -3.65114223e-01, -3.15429907e-01,\n",
       "       -8.05687151e-02,  4.05919365e-01,  2.15672137e-01,  2.08376369e-01,\n",
       "       -9.50154712e-01,  4.68321486e-01,  4.20866429e-01,  2.28563971e-01,\n",
       "       -2.03202247e-01, -7.15578480e-01,  2.88752474e-01,  9.45741623e-01,\n",
       "       -6.80582187e-01, -5.09190994e-01,  3.90661298e-02,  7.33735868e-01,\n",
       "        6.48507152e-01, -4.72464826e-01, -8.43432841e-01,  8.18652315e-01,\n",
       "        4.15706620e-01,  2.32960069e-01,  5.35044745e-01, -5.75856677e-02,\n",
       "        8.91035532e-01, -6.75914588e-01, -5.83973330e-01,  2.03470615e-01,\n",
       "        6.56755476e-01,  9.87404829e-01, -7.04482572e-01,  8.36617678e-01,\n",
       "       -1.29527882e-01, -2.38274555e-01, -7.11766741e-02,  5.58917672e-01,\n",
       "        6.78695550e-03, -6.12355894e-01,  5.89553643e-01, -2.46619024e-01,\n",
       "       -1.24183365e-02,  6.89347847e-01,  7.34275250e-01, -2.70463845e-02,\n",
       "        4.12103263e-01,  3.66727015e-01, -7.49406885e-01, -2.27227085e-01,\n",
       "        6.94407838e-01,  8.35193353e-01,  6.18945955e-02, -1.40859475e-01,\n",
       "        7.83451286e-01, -5.93937818e-01,  5.37786236e-01,  8.77256705e-01,\n",
       "       -9.58570189e-01, -8.56551161e-01, -3.45388348e-01, -9.79912831e-01,\n",
       "       -6.44197832e-01, -4.29343429e-01, -4.33434340e-01, -1.21375867e-01,\n",
       "       -4.78772726e-01,  3.52895797e-01,  4.31507478e-02, -2.96114858e-01,\n",
       "       -7.22473171e-01, -3.15446634e-01,  2.03526520e-01,  9.55620493e-01,\n",
       "       -8.04183336e-01, -2.22103298e-01,  1.75904958e-01, -2.05750550e-01,\n",
       "       -3.31359961e-01, -9.05450749e-01,  1.24452872e-01, -3.86278472e-01,\n",
       "       -4.35978433e-01, -5.49467255e-01, -6.54069621e-01, -4.11983514e-01,\n",
       "        5.48950799e-02,  8.99734823e-01,  7.93468168e-02,  9.56728123e-01,\n",
       "       -6.01461755e-01, -9.58548180e-01,  7.86493071e-01,  6.36566779e-02,\n",
       "       -3.81289020e-02, -4.53505525e-01,  8.31962828e-02, -1.73347654e-01,\n",
       "        5.23321136e-02,  2.09213969e-01, -1.35779344e-01, -7.12064978e-01,\n",
       "        9.92762453e-02, -7.56920650e-01, -2.37438896e-01,  5.14014090e-01,\n",
       "       -1.48918478e-01,  1.24620604e-01, -4.83421564e-01, -1.37356894e-02,\n",
       "       -4.32173757e-01,  1.02886273e-01,  7.30198967e-01, -9.42424245e-01,\n",
       "        8.51628064e-01, -7.36029203e-01,  7.69223146e-01,  9.64263577e-01,\n",
       "        5.94968025e-01,  4.76880453e-01,  5.92439826e-01,  8.08811868e-02,\n",
       "        8.72716996e-01,  7.33888346e-01,  6.22284194e-01, -7.79711625e-01,\n",
       "        7.33468892e-01, -3.70071756e-01, -1.71153550e-01,  2.37097570e-01,\n",
       "        9.63145175e-01, -9.25614337e-01, -7.55464648e-01, -8.24188262e-01,\n",
       "       -3.65328939e-01,  4.05978220e-01,  2.29059867e-01, -8.44774201e-01,\n",
       "       -6.59214189e-01, -4.72854940e-01,  7.80788900e-01, -9.18209834e-02,\n",
       "        8.86388351e-01,  5.43410111e-01, -6.28084609e-01,  8.52004348e-01,\n",
       "       -9.90029337e-01, -5.89051474e-01, -5.45654538e-01,  9.36195079e-01,\n",
       "       -3.86994776e-02,  6.03694366e-01, -6.52190645e-01, -1.04603429e-01,\n",
       "        2.61099100e-01, -8.11922825e-02, -7.97816768e-01, -7.38718250e-01,\n",
       "        4.57648983e-01, -3.17692005e-01, -8.68578087e-02, -4.61800330e-01,\n",
       "       -9.28756748e-01, -4.52915879e-01,  8.52486925e-01,  9.48323959e-01,\n",
       "       -3.87209078e-01, -2.47296441e-01,  8.92882228e-01, -4.00580737e-01,\n",
       "       -5.99453188e-01, -8.56864922e-01,  6.44200156e-01, -7.46067892e-01,\n",
       "        6.58304320e-02, -9.27936387e-01, -1.54437791e-01,  9.71911955e-01,\n",
       "       -2.08572180e-01, -8.78817700e-01, -6.71212186e-01,  9.01166187e-01,\n",
       "        1.67663621e-01, -4.80502728e-01, -3.36418104e-01, -9.70985833e-01,\n",
       "        7.49386541e-01,  2.36963468e-01,  1.92674073e-01,  9.72827665e-01,\n",
       "        5.09210182e-01, -5.66932904e-01,  3.35319488e-01,  1.71210187e-01,\n",
       "        2.61571618e-01,  7.68797012e-01, -3.40409330e-01,  2.26612813e-01,\n",
       "       -3.19681389e-01, -7.81880439e-01, -4.90742241e-01, -3.73036171e-01,\n",
       "        5.41006349e-01, -2.61784996e-01, -1.92026055e-01,  6.53248316e-01,\n",
       "       -9.40938205e-01, -7.15902112e-02,  9.90430276e-01,  2.41606417e-01,\n",
       "       -9.57819229e-01,  2.78655107e-01, -9.71821893e-02, -6.59244104e-01,\n",
       "       -7.34550332e-01,  7.33025151e-02,  9.20581882e-01, -2.60358456e-01,\n",
       "        1.26230622e-01,  5.02094793e-01, -6.89361645e-01,  5.94202892e-01,\n",
       "       -7.33030319e-01, -6.62077513e-01,  7.45491773e-01, -5.75607042e-01,\n",
       "       -7.56580647e-01, -8.19200963e-01,  6.27976986e-01, -9.40757671e-01,\n",
       "        7.20932707e-01,  4.18215433e-01, -3.82672018e-01,  5.76028185e-01,\n",
       "        4.91237689e-01,  2.70837456e-01, -5.86792118e-01,  1.56501424e-01,\n",
       "       -9.23760727e-01,  1.15890744e-01, -2.17863437e-01,  3.35374569e-01,\n",
       "       -7.92845110e-01, -4.44154191e-01, -7.19902646e-01,  1.02428986e-01,\n",
       "       -3.46091710e-01, -3.14090066e-01,  8.24486377e-01, -2.68870992e-01,\n",
       "        6.63514471e-01, -5.41818038e-01,  6.88264769e-01,  8.95216125e-01,\n",
       "       -4.99941643e-01,  2.12056255e-01, -8.58328082e-02, -1.61796517e-01,\n",
       "       -3.52954906e-01,  1.22451802e-01,  1.90081511e-01, -7.18884887e-01,\n",
       "       -3.71407239e-01, -9.11022555e-01, -5.71950452e-01,  6.26307925e-01,\n",
       "        2.76449945e-01, -7.73243656e-01, -9.40092797e-01, -8.03381871e-01,\n",
       "        2.97667159e-01,  1.52680831e-01,  9.81840458e-02, -4.69531746e-01,\n",
       "       -3.66339648e-01,  4.67852504e-01, -3.40752093e-01, -8.37350071e-02,\n",
       "        7.77819400e-01,  2.89728729e-01, -5.82036915e-01,  2.70815821e-01,\n",
       "       -3.45839026e-01, -7.47513306e-01, -9.17665638e-01,  5.74003926e-01,\n",
       "        3.01620559e-01,  6.52399550e-01,  5.30880271e-01,  6.03887620e-01,\n",
       "        9.82472574e-01,  4.45005094e-01,  9.47294155e-01, -2.45715652e-01,\n",
       "       -6.04018239e-01, -9.07730288e-01, -7.74607239e-01,  7.46981505e-01,\n",
       "       -1.30829668e-01, -4.54641195e-01, -6.63735768e-01,  6.86821749e-01,\n",
       "       -8.43559039e-01,  7.44070060e-01,  6.36146013e-01,  3.03375483e-01,\n",
       "       -4.38583670e-01, -9.09717464e-01,  4.22289744e-02, -4.48156652e-01,\n",
       "        4.80237514e-01,  9.29443531e-01, -3.04344838e-01,  2.13392882e-02,\n",
       "       -7.06208628e-01,  1.39016886e-01, -1.82171155e-01, -4.57894880e-01,\n",
       "        7.51318786e-01, -8.76891686e-01,  2.28344683e-02,  9.99857395e-01,\n",
       "        3.72614861e-01,  5.87657901e-01, -8.45061948e-01, -4.04382596e-01,\n",
       "       -2.27800562e-02,  9.74596075e-01,  4.37688030e-01,  2.72754931e-01,\n",
       "       -3.67360443e-01,  7.11417855e-03, -7.21189465e-01, -4.44721191e-01,\n",
       "        1.29704523e-01,  5.98914254e-01,  1.91535035e-01, -3.74092532e-01,\n",
       "        4.73033866e-01, -1.65424921e-01,  1.59937159e-01, -6.84978540e-01,\n",
       "        2.81800222e-01,  2.87923818e-02,  5.19063763e-01,  8.04614742e-01,\n",
       "        7.14289598e-01, -1.92090471e-01,  6.82093696e-01, -4.99748920e-01,\n",
       "       -4.22921537e-01, -8.26550953e-01,  5.89883811e-01, -5.40057930e-01,\n",
       "        5.56262801e-01,  9.27097733e-02, -5.66733776e-01, -4.19060119e-01,\n",
       "       -1.17285195e-01, -8.87538758e-01,  1.42652459e-02, -6.06499249e-01,\n",
       "       -7.98987286e-02, -3.87104121e-01, -2.24417143e-01, -8.97838621e-01,\n",
       "        8.37511048e-01,  8.16043439e-01, -3.50102128e-01, -4.18664574e-01,\n",
       "       -3.88975868e-01, -7.76686468e-01, -8.88657793e-01, -7.92497346e-01,\n",
       "        8.74065171e-01,  2.53588127e-01,  1.74831009e-01,  9.41130587e-01,\n",
       "       -1.07452817e-01, -3.30088391e-01, -3.30061762e-01,  8.22663463e-01,\n",
       "        4.71950645e-01,  5.71166683e-01,  9.90557886e-01, -6.33255677e-01,\n",
       "       -6.25143676e-01,  3.93383688e-01,  1.56336735e-01, -7.79834026e-01,\n",
       "       -7.87744707e-01, -7.13823351e-01, -6.36443924e-01,  6.05930291e-01,\n",
       "        7.77436255e-01, -7.62978030e-03, -8.69578951e-01, -3.57831151e-01,\n",
       "        6.26502971e-01,  5.46561341e-02, -6.32176269e-01, -3.59782760e-01,\n",
       "        3.91073607e-01,  3.34657197e-01, -8.64293941e-01, -7.06811035e-01,\n",
       "        8.09666384e-01, -6.48014493e-01, -9.42613678e-01,  4.12098442e-01,\n",
       "       -8.35624876e-01, -2.66502828e-01,  2.56548906e-01,  7.18452030e-01,\n",
       "       -4.09041151e-01, -2.37723565e-01,  4.16991346e-01, -7.73158330e-01,\n",
       "        3.48311658e-01,  4.34373538e-02, -1.14351723e-01, -8.61366579e-01,\n",
       "        7.46413061e-01,  6.08412307e-01,  1.06397269e-01,  9.26604189e-01,\n",
       "        5.29350554e-01, -1.16252465e-01,  8.52884268e-01, -2.32418652e-01,\n",
       "        1.49946023e-01, -2.32791642e-01,  1.17486593e-01,  7.10459332e-01,\n",
       "        1.25362569e-01,  7.61646441e-02, -3.13938387e-02,  7.97302715e-01,\n",
       "       -6.42400147e-01, -7.75776383e-01,  5.44517469e-01, -6.74086951e-01,\n",
       "       -6.07257818e-01,  3.56483963e-01,  5.53615944e-01,  8.33244764e-01,\n",
       "        7.34208631e-01,  8.20957893e-01, -4.98329138e-01,  9.72278471e-01,\n",
       "       -4.84383714e-01, -6.38731486e-01,  6.12573925e-01,  1.20398886e-02,\n",
       "        4.86702930e-01,  6.76969884e-01,  4.85612054e-01, -3.90253865e-01,\n",
       "       -4.19585738e-01,  6.31022039e-01, -5.66994045e-01, -8.69039472e-01,\n",
       "        2.50278587e-01,  7.43859463e-01,  3.71392724e-01,  7.79600039e-01,\n",
       "       -7.17150479e-01,  2.65332779e-01, -3.46325972e-01, -6.82326049e-01,\n",
       "       -9.03413131e-01,  2.32629040e-01,  4.84471047e-01,  5.85721398e-01,\n",
       "        7.51330215e-01,  9.64044476e-01,  1.59115027e-01, -3.30295989e-02,\n",
       "        7.40045090e-01, -2.14532351e-01, -3.14478153e-01, -6.17663518e-01,\n",
       "       -4.84302512e-01,  8.10638145e-01,  2.73086149e-01, -6.75884958e-02,\n",
       "        4.19328938e-01, -9.48131361e-02, -2.35007563e-01, -4.77584037e-01,\n",
       "       -6.59990739e-01,  1.96110345e-01, -5.89775457e-01, -9.91500789e-01,\n",
       "       -4.65090312e-01,  6.49772376e-01, -8.61510622e-02,  7.96100644e-01,\n",
       "        9.12719449e-01,  2.08799875e-03, -3.61232160e-01, -7.33739129e-01,\n",
       "        9.58487632e-01, -9.34013073e-01, -9.26394843e-01, -6.87767289e-02,\n",
       "       -4.75758150e-01, -3.20541305e-01, -6.39798282e-01, -7.83566336e-01,\n",
       "        5.05265551e-01, -8.82932393e-01,  1.66013701e-01, -8.22950320e-01,\n",
       "        1.03174988e-01, -4.68007772e-01,  5.11977608e-01,  6.12073157e-01,\n",
       "        5.67627847e-01,  1.07265373e-02,  8.17680051e-01, -5.92929672e-01,\n",
       "       -6.60297108e-01, -6.29140218e-01,  7.50048127e-01, -6.47009289e-01,\n",
       "       -7.00095193e-01, -3.40931164e-01,  7.54085993e-01, -7.57000323e-01,\n",
       "        6.62372964e-01,  6.16014639e-01, -3.51093348e-01,  6.26254000e-01,\n",
       "       -2.53295755e-01, -8.43745620e-04, -7.60211390e-01,  1.86300775e-01,\n",
       "        8.54232250e-01,  3.58645764e-01, -1.81582482e-01, -1.56910874e-01,\n",
       "        5.74308281e-01,  7.00336516e-01,  8.58097784e-02,  5.05560706e-01,\n",
       "        9.79590108e-01, -7.71456752e-01, -4.07032296e-01, -8.90622921e-01,\n",
       "        3.76564931e-01,  8.12531056e-01, -5.68157945e-01,  5.59338048e-01,\n",
       "       -9.08827640e-01, -6.90310914e-01,  9.69064154e-01, -6.02153944e-01,\n",
       "       -7.01464292e-01, -9.75922616e-01,  2.15461022e-01, -3.25089362e-01,\n",
       "        1.57383663e-03,  2.09652755e-01, -4.16010292e-02,  9.45500199e-01,\n",
       "       -1.53664547e-01,  7.82593752e-01, -4.27563366e-01, -4.30849637e-01,\n",
       "       -3.20272341e-01,  9.66776072e-01, -2.16146663e-01,  7.13321802e-01,\n",
       "       -7.52598916e-01, -2.93278261e-01, -4.66370499e-01,  2.09930313e-01,\n",
       "       -8.32828591e-01, -9.06683260e-01, -2.50828937e-01, -7.49386992e-01,\n",
       "        1.08212229e-02, -1.32174010e-01,  7.79891418e-01, -7.49496251e-01,\n",
       "        4.82172068e-01,  6.93210929e-01, -6.27427782e-01,  1.55076291e-03,\n",
       "       -2.55735255e-01, -2.78272716e-01,  6.64871829e-01, -5.32525735e-01,\n",
       "       -8.13807001e-01,  3.76625324e-01,  1.37477285e-01, -7.59645814e-01,\n",
       "       -3.75603983e-01, -6.67296525e-01, -6.39646028e-01,  3.67099735e-01,\n",
       "       -1.62251967e-01, -7.35726143e-01, -2.96585437e-01, -6.91537488e-01,\n",
       "       -9.06124452e-01, -1.08452950e-01,  1.98281231e-01,  5.54059120e-01,\n",
       "       -3.78629778e-01, -1.57303246e-01, -9.07264144e-01, -1.96443750e-01,\n",
       "        3.98726598e-01, -7.78065525e-01,  1.77879690e-01,  3.54378189e-01,\n",
       "       -1.25748250e-01,  9.77117564e-01, -8.83680234e-01,  3.61838200e-01,\n",
       "       -7.27964246e-02,  3.29964145e-02, -7.70213205e-01, -8.75008473e-01,\n",
       "       -2.72656864e-01,  7.99192586e-01, -3.14867183e-01, -5.91619418e-01,\n",
       "       -5.64571545e-01,  9.28078456e-01, -5.71254827e-01,  8.89418842e-01,\n",
       "       -9.87130524e-01, -4.98997588e-01,  3.57916839e-01, -2.43377128e-01,\n",
       "        4.62711935e-01,  1.27693317e-01,  1.76146165e-01, -6.49349741e-01,\n",
       "        6.18208569e-01,  6.35204254e-02,  2.88336277e-01,  7.56617776e-01,\n",
       "        9.09367431e-01, -6.66821134e-02, -5.07265623e-01,  9.23909786e-01,\n",
       "       -6.47934145e-01, -3.75530451e-01, -7.65905812e-02, -6.37084345e-01,\n",
       "        5.33440390e-01,  6.89398331e-01, -6.23450517e-01, -1.77420880e-02,\n",
       "       -3.86971359e-01, -3.36440726e-01,  5.29692739e-01,  1.27938928e-02,\n",
       "       -6.42420561e-01, -1.62441460e-01, -7.51866912e-01, -6.50527597e-01,\n",
       "       -5.85681667e-01, -7.66389694e-01,  1.62591200e-02, -2.04373683e-01,\n",
       "       -9.89994332e-01, -1.91085232e-01,  9.63706948e-02, -2.77400961e-01,\n",
       "       -9.16794899e-01, -4.18783411e-01, -9.74838480e-01,  7.27265956e-01,\n",
       "        7.03401480e-01, -6.48119286e-01,  1.52302696e-01,  9.77391026e-02,\n",
       "        4.03679698e-02, -8.48756747e-01,  7.14930490e-01, -5.53176948e-01,\n",
       "       -7.02876459e-01, -2.05028240e-01,  7.30693226e-01,  6.68054923e-01,\n",
       "        5.29136652e-01,  8.23584651e-01, -9.38295205e-01, -9.74226650e-01,\n",
       "        2.21845460e-01,  2.29351902e-01, -5.53865995e-01,  7.20432934e-02,\n",
       "        4.85003879e-01, -3.88533443e-01, -3.52556554e-01, -1.79982014e-01,\n",
       "        2.23108204e-01,  8.14930639e-01,  1.64705324e-01,  3.10615045e-01,\n",
       "       -1.02838319e-01, -3.85525368e-02, -2.06370404e-01,  4.03259287e-02,\n",
       "       -3.90259453e-01,  3.11244995e-01,  4.56923612e-01,  9.54239834e-01,\n",
       "       -7.93617978e-01,  3.15683705e-01, -9.37829893e-01,  3.51409024e-01,\n",
       "        5.87610029e-01,  2.09528639e-01,  6.54559624e-01,  7.30763149e-01,\n",
       "       -1.41040401e-01,  9.09548569e-01,  4.39487923e-01,  4.29517645e-01,\n",
       "        6.51775990e-01, -3.32335444e-01,  7.74909523e-01, -9.65438663e-01,\n",
       "        8.47529038e-01, -3.45040100e-01, -5.82873239e-01, -4.36419578e-01,\n",
       "       -8.92383640e-01,  1.61199682e-01,  5.40422866e-02,  9.31160199e-01,\n",
       "        4.01965033e-01, -6.35072118e-01,  6.03968176e-01,  5.19766188e-01,\n",
       "        6.09951469e-01,  3.88800532e-01,  6.93928303e-01,  6.69299364e-01,\n",
       "        5.40958547e-01,  9.81368380e-02, -1.03813593e-01, -2.06629180e-01,\n",
       "       -2.52241632e-01, -2.20167700e-01,  8.35103689e-01,  5.74535894e-01,\n",
       "       -7.02564690e-01, -1.03424269e-01, -5.13704900e-01, -2.86369409e-01,\n",
       "        8.60598779e-01,  6.35851621e-01,  4.80403862e-01, -3.96057482e-01,\n",
       "        7.73976787e-01,  9.67216218e-01,  3.34437145e-02, -7.46395794e-01,\n",
       "        2.97501207e-01,  2.70580582e-01, -5.32622078e-01,  3.94227425e-01,\n",
       "       -4.83310659e-01, -7.46504904e-01,  2.71795868e-01, -8.66160654e-01,\n",
       "        1.75613339e-01, -3.52214591e-02,  2.95408471e-01,  3.08873496e-01,\n",
       "       -4.11584334e-01,  5.91590243e-01, -3.61260620e-01, -5.22756841e-01,\n",
       "       -3.66057259e-01,  1.38749760e-02, -2.53198736e-01, -9.67088523e-01,\n",
       "       -4.88288569e-01,  5.33093092e-01, -7.43072408e-02,  2.86848352e-01,\n",
       "       -6.43175747e-01,  9.48106408e-01, -1.00013969e-01, -4.64413204e-02,\n",
       "       -9.81151391e-01,  8.91148823e-01, -3.48081719e-01, -2.35175444e-01,\n",
       "        1.69228372e-01, -9.21317472e-01,  6.70354302e-02,  4.36973736e-01,\n",
       "        1.05173848e-01,  1.58927081e-01, -9.52442989e-01,  8.07630753e-02,\n",
       "        4.58977957e-01, -3.30117159e-02,  9.07878059e-01, -5.31736500e-01,\n",
       "       -6.51917141e-02, -1.40152218e-01,  9.04307938e-01,  1.57356257e-01,\n",
       "        6.18294502e-01, -9.81558561e-01, -9.50496224e-01,  1.26541664e-04,\n",
       "        2.80671738e-01,  2.95474456e-01, -7.02712990e-01,  3.27474410e-01,\n",
       "        6.76561350e-01, -7.69152291e-01, -7.06337093e-01, -3.05372192e-01,\n",
       "       -1.19356271e-03,  2.17690804e-01,  1.58292379e-01, -4.72854186e-02,\n",
       "        9.50029165e-01, -8.70899050e-01, -5.76551503e-01,  3.43772432e-01,\n",
       "       -6.41036628e-01,  1.10365805e-02,  2.35515281e-01, -8.49437831e-01,\n",
       "        8.79042585e-01, -4.95394599e-01, -2.89663468e-01, -5.53785810e-01,\n",
       "        3.84508750e-01, -7.44170476e-01, -3.84276954e-01, -6.18686158e-01,\n",
       "        1.93443236e-01,  6.54211916e-01, -7.09031250e-01,  8.77005524e-01,\n",
       "       -5.57324469e-01, -7.74365910e-01,  1.07347831e-01,  4.94883961e-01,\n",
       "        8.74081180e-03, -4.00351152e-01, -4.74463798e-01,  6.41253842e-02,\n",
       "        1.88885830e-01,  1.12673658e-01, -1.67501611e-01, -1.32134140e-01,\n",
       "       -1.68244754e-01, -1.54835673e-01, -3.47298226e-01,  5.86852009e-01,\n",
       "        2.93615951e-01, -7.43208312e-01,  1.14560757e-01, -9.91430992e-01,\n",
       "        8.65471589e-01, -1.64681386e-01,  6.49915339e-01,  7.61892862e-01])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = max_tokens\n",
    "vocabulary_size = num_words\n",
    "embedding_dim = embedding_size\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 512\n",
    "drop = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train2 = np.array([])\n",
    "y_test2 = np.array([])\n",
    "for i in y_train:\n",
    "    y_train2 = np.append(y_train2, i)\n",
    "for i in y_test:\n",
    "    y_test2 =np.append(y_test2, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training CNN ...\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_layer (Embedding)  (None, 16, 1000)          14369000  \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 16, 16)            112016    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 8, 16)             1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 14,483,434\n",
      "Trainable params: 14,483,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/25\n",
      "86/86 - 12s - loss: 0.7398 - accuracy: 0.5466 - val_loss: 0.6874 - val_accuracy: 0.5731\n",
      "Epoch 2/25\n",
      "86/86 - 12s - loss: 0.6863 - accuracy: 0.5698 - val_loss: 0.6804 - val_accuracy: 0.5977\n",
      "Epoch 3/25\n",
      "86/86 - 12s - loss: 0.6659 - accuracy: 0.6079 - val_loss: 0.6475 - val_accuracy: 0.6371\n",
      "Epoch 4/25\n",
      "86/86 - 12s - loss: 0.6225 - accuracy: 0.6563 - val_loss: 0.5902 - val_accuracy: 0.7094\n",
      "Epoch 5/25\n",
      "86/86 - 12s - loss: 0.5665 - accuracy: 0.7072 - val_loss: 0.5410 - val_accuracy: 0.7389\n",
      "Epoch 6/25\n",
      "86/86 - 11s - loss: 0.4956 - accuracy: 0.7590 - val_loss: 0.5028 - val_accuracy: 0.7603\n",
      "Epoch 7/25\n",
      "86/86 - 12s - loss: 0.4255 - accuracy: 0.7975 - val_loss: 0.5156 - val_accuracy: 0.7668\n",
      "Epoch 8/25\n",
      "86/86 - 12s - loss: 0.3806 - accuracy: 0.8254 - val_loss: 0.5356 - val_accuracy: 0.7701\n",
      "Epoch 9/25\n",
      "86/86 - 12s - loss: 0.3469 - accuracy: 0.8387 - val_loss: 0.5747 - val_accuracy: 0.7701\n",
      "Epoch 10/25\n",
      "86/86 - 11s - loss: 0.3078 - accuracy: 0.8548 - val_loss: 0.6089 - val_accuracy: 0.7668\n",
      "Epoch 11/25\n",
      "86/86 - 12s - loss: 0.2781 - accuracy: 0.8716 - val_loss: 0.6469 - val_accuracy: 0.7718\n",
      "Epoch 12/25\n",
      "86/86 - 12s - loss: 0.2618 - accuracy: 0.8747 - val_loss: 0.6753 - val_accuracy: 0.7750\n",
      "Epoch 13/25\n",
      "86/86 - 12s - loss: 0.2465 - accuracy: 0.8820 - val_loss: 0.7466 - val_accuracy: 0.7685\n",
      "Epoch 14/25\n",
      "86/86 - 12s - loss: 0.2244 - accuracy: 0.8905 - val_loss: 0.7648 - val_accuracy: 0.7767\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "#CNN architecture\n",
    "\n",
    "num_classes = 2\n",
    "\n",
    "#Training params\n",
    "batch_size = 64 \n",
    "num_epochs = 25\n",
    "\n",
    "#Model parameters\n",
    "num_filters = 16  # grntnn boyutu mesela 512*512\n",
    "embed_dim = embedding_size \n",
    "weight_decay = 1e-4\n",
    "\n",
    "print(\"training CNN ...\")\n",
    "model = Sequential()\n",
    "\n",
    "#Model add word2vec embedding\n",
    "\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    weights= [embedding_matrix],\n",
    "                    input_length=max_tokens,        \n",
    "                    trainable=True,              #the layer is trained\n",
    "                    name='embedding_layer'))\n",
    "model.add(Conv1D(num_filters, 7, activation='tanh', padding='same'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(num_filters, 7, activation='tanh', padding='same'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dropout(0.9))\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Dense(num_classes, activation='softmax'))  #multi-label (k-hot encoding)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "#define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=8, verbose=1)\n",
    "callbacks_list = [early_stopping]\n",
    "\n",
    "\n",
    "hist = model.fit(x_train_pad, y_train2, batch_size=batch_size, epochs=num_epochs, callbacks=callbacks_list, validation_split=0.1, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7537754432042022"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(x_test_pad)\n",
    "predicted =np.argmax(predicted, axis=1) \n",
    "np.mean(predicted == y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
